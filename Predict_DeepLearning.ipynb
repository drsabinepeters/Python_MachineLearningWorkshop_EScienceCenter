{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First I start with loading a datafile which is a subset of the complete data\n",
    "\n",
    "# I start with an elastic net regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(os.path.expanduser('~/surfdrive/SamenUniek/Projects/2020_ML_Amsterdam/'))\n",
    "\n",
    "# read data\n",
    "data = pd.read_csv('Datasets/SamenUniek_all_Data_w01w03_ML_AMS_2020_randomized_V2.csv')\n",
    "\n",
    "# make new variable Age, which consists of the age at the timepoint of measuresment \n",
    "data['AgeYears'] = np.where(data['visit'] == 1, data['C3.1_AgeMonths'], data['C3.3_AgeMonths'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all data columns (wihtout the ...)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ChildID', 'FamilyID', 'GenderTwin', 'C3.1_AgeMonths', 'C3.3_AgeMonths', 'C3.1_DNA_Zygosity', 'C3.3_SRS_TotalScore_18', 'EstimatedIQ', 'SocioEconomicStatus', 'C3.3_Stop_Total_CorrectGO', 'C3.3_Stop_Total_CorrectNOGO', 'C3.3_Stop_Total_Mean_corGO_RT', 'visit', 'AgeYears', 'Left.Cerebellum.White.Matter', 'Left.Cerebellum.Cortex', 'Left.Thalamus.Proper', 'Left.Caudate', 'Left.Putamen', 'Left.Pallidum', 'Left.Hippocampus', 'Left.Amygdala', 'Left.Accumbens.area', 'Right.Cerebellum.White.Matter', 'Right.Cerebellum.Cortex', 'Right.Thalamus.Proper', 'Right.Caudate', 'Right.Putamen', 'Right.Pallidum', 'Right.Hippocampus', 'Right.Amygdala', 'Right.Accumbens.area', 'CC_Posterior', 'CC_Mid_Posterior', 'CC_Central', 'CC_Mid_Anterior', 'CC_Anterior', 'lhCortexVol', 'rhCortexVol', 'CortexVol', 'SubCortGrayVol', 'TotalGrayVol', 'lh_caudalanteriorcingulate_area', 'lh_caudalmiddlefrontal_area', 'lh_cuneus_area', 'lh_entorhinal_area', 'lh_fusiform_area', 'lh_inferiorparietal_area', 'lh_inferiortemporal_area', 'lh_isthmuscingulate_area', 'lh_lateraloccipital_area', 'lh_lateralorbitofrontal_area', 'lh_lingual_area', 'lh_medialorbitofrontal_area', 'lh_middletemporal_area', 'lh_parahippocampal_area', 'lh_paracentral_area', 'lh_parsopercularis_area', 'lh_parsorbitalis_area', 'lh_parstriangularis_area', 'lh_pericalcarine_area', 'lh_postcentral_area', 'lh_posteriorcingulate_area', 'lh_precentral_area', 'lh_precuneus_area', 'lh_rostralanteriorcingulate_area', 'lh_rostralmiddlefrontal_area', 'lh_superiorfrontal_area', 'lh_superiorparietal_area', 'lh_superiortemporal_area', 'lh_supramarginal_area', 'lh_transversetemporal_area', 'lh_insula_area', 'lh_WhiteSurfArea_area', 'rh_caudalanteriorcingulate_area', 'rh_caudalmiddlefrontal_area', 'rh_cuneus_area', 'rh_entorhinal_area', 'rh_fusiform_area', 'rh_inferiorparietal_area', 'rh_inferiortemporal_area', 'rh_isthmuscingulate_area', 'rh_lateraloccipital_area', 'rh_lateralorbitofrontal_area', 'rh_lingual_area', 'rh_medialorbitofrontal_area', 'rh_middletemporal_area', 'rh_parahippocampal_area', 'rh_paracentral_area', 'rh_parsopercularis_area', 'rh_parsorbitalis_area', 'rh_parstriangularis_area', 'rh_pericalcarine_area', 'rh_postcentral_area', 'rh_posteriorcingulate_area', 'rh_precentral_area', 'rh_precuneus_area', 'rh_rostralanteriorcingulate_area', 'rh_rostralmiddlefrontal_area', 'rh_superiorfrontal_area', 'rh_superiorparietal_area', 'rh_superiortemporal_area', 'rh_supramarginal_area', 'rh_transversetemporal_area', 'rh_insula_area', 'rh_WhiteSurfArea_area', 'lh_caudalanteriorcingulate_thickness', 'lh_caudalmiddlefrontal_thickness', 'lh_cuneus_thickness', 'lh_entorhinal_thickness', 'lh_fusiform_thickness', 'lh_inferiorparietal_thickness', 'lh_inferiortemporal_thickness', 'lh_isthmuscingulate_thickness', 'lh_lateraloccipital_thickness', 'lh_lateralorbitofrontal_thickness', 'lh_lingual_thickness', 'lh_medialorbitofrontal_thickness', 'lh_middletemporal_thickness', 'lh_parahippocampal_thickness', 'lh_paracentral_thickness', 'lh_parsopercularis_thickness', 'lh_parsorbitalis_thickness', 'lh_parstriangularis_thickness', 'lh_pericalcarine_thickness', 'lh_postcentral_thickness', 'lh_posteriorcingulate_thickness', 'lh_precentral_thickness', 'lh_precuneus_thickness', 'lh_rostralanteriorcingulate_thickness', 'lh_rostralmiddlefrontal_thickness', 'lh_superiorfrontal_thickness', 'lh_superiorparietal_thickness', 'lh_superiortemporal_thickness', 'lh_supramarginal_thickness', 'lh_transversetemporal_thickness', 'lh_insula_thickness', 'lh_MeanThickness_thickness', 'rh_caudalanteriorcingulate_thickness', 'rh_caudalmiddlefrontal_thickness', 'rh_cuneus_thickness', 'rh_entorhinal_thickness', 'rh_fusiform_thickness', 'rh_inferiorparietal_thickness', 'rh_inferiortemporal_thickness', 'rh_isthmuscingulate_thickness', 'rh_lateraloccipital_thickness', 'rh_lateralorbitofrontal_thickness', 'rh_lingual_thickness', 'rh_medialorbitofrontal_thickness', 'rh_middletemporal_thickness', 'rh_parahippocampal_thickness', 'rh_paracentral_thickness', 'rh_parsopercularis_thickness', 'rh_parsorbitalis_thickness', 'rh_parstriangularis_thickness', 'rh_pericalcarine_thickness', 'rh_postcentral_thickness', 'rh_posteriorcingulate_thickness', 'rh_precentral_thickness', 'rh_precuneus_thickness', 'rh_rostralanteriorcingulate_thickness', 'rh_rostralmiddlefrontal_thickness', 'rh_superiorfrontal_thickness', 'rh_superiorparietal_thickness', 'rh_superiortemporal_thickness', 'rh_supramarginal_thickness', 'rh_transversetemporal_thickness', 'rh_insula_thickness', 'rh_MeanThickness_thickness', 'ChildID2']\n",
      "     ChildID  FamilyID GenderTwin  C3.1_AgeMonths  C3.3_AgeMonths  \\\n",
      "0        601         6       boys            89.0           114.0   \n",
      "1        701         7       boys            89.0           113.0   \n",
      "2        901         9       boys            87.0           111.0   \n",
      "3        902         9       boys            87.0           111.0   \n",
      "4       1301        13       boys            92.0           116.0   \n",
      "..       ...       ...        ...             ...             ...   \n",
      "584   115702      1157      girls            87.0           111.0   \n",
      "585   116401      1164      girls            86.0           109.0   \n",
      "586   116402      1164      girls            86.0           109.0   \n",
      "587   117401      1174      girls             NaN           137.0   \n",
      "588   117402      1174      girls             NaN           137.0   \n",
      "\n",
      "    C3.1_DNA_Zygosity  C3.3_SRS_TotalScore_18  EstimatedIQ  \\\n",
      "0                  DZ                     2.0         87.5   \n",
      "1                  DZ                     NaN         97.5   \n",
      "2                  MZ                     2.0         97.5   \n",
      "3                  MZ                     3.0         95.0   \n",
      "4                  MZ                     2.0         82.5   \n",
      "..                ...                     ...          ...   \n",
      "584                DZ                     6.0         97.5   \n",
      "585                MZ                    11.0         82.5   \n",
      "586                MZ                     8.0        100.0   \n",
      "587               NaN                     6.0          NaN   \n",
      "588               NaN                     7.0          NaN   \n",
      "\n",
      "    SocioEconomicStatus  C3.3_Stop_Total_CorrectGO  ...  \\\n",
      "0              high SES                  99.342105  ...   \n",
      "1            middle SES                  99.342105  ...   \n",
      "2            middle SES                  92.105263  ...   \n",
      "3            middle SES                  96.710526  ...   \n",
      "4            middle SES                  99.342105  ...   \n",
      "..                  ...                        ...  ...   \n",
      "584          middle SES                  83.552632  ...   \n",
      "585            high SES                  94.078947  ...   \n",
      "586            high SES                  99.342105  ...   \n",
      "587          middle SES                  94.736842  ...   \n",
      "588          middle SES                  98.684211  ...   \n",
      "\n",
      "     rh_rostralanteriorcingulate_thickness  rh_rostralmiddlefrontal_thickness  \\\n",
      "0                                    3.894                              2.957   \n",
      "1                                    3.815                              2.899   \n",
      "2                                    4.122                              2.822   \n",
      "3                                    3.659                              2.912   \n",
      "4                                    2.953                              2.708   \n",
      "..                                     ...                                ...   \n",
      "584                                  2.533                              2.705   \n",
      "585                                  2.494                              2.717   \n",
      "586                                  2.612                              2.809   \n",
      "587                                  3.383                              2.964   \n",
      "588                                  3.408                              2.751   \n",
      "\n",
      "     rh_superiorfrontal_thickness  rh_superiorparietal_thickness  \\\n",
      "0                           3.253                          2.828   \n",
      "1                           3.446                          2.881   \n",
      "2                           3.407                          2.614   \n",
      "3                           3.433                          2.418   \n",
      "4                           2.741                          2.156   \n",
      "..                            ...                            ...   \n",
      "584                         3.208                          2.394   \n",
      "585                         2.921                          2.456   \n",
      "586                         3.125                          2.064   \n",
      "587                         3.265                          2.588   \n",
      "588                         3.361                          2.608   \n",
      "\n",
      "     rh_superiortemporal_thickness  rh_supramarginal_thickness  \\\n",
      "0                            3.209                       3.008   \n",
      "1                            3.325                       3.192   \n",
      "2                            2.960                       2.976   \n",
      "3                            3.051                       2.969   \n",
      "4                            2.129                       2.026   \n",
      "..                             ...                         ...   \n",
      "584                          2.595                       2.871   \n",
      "585                          1.783                       2.833   \n",
      "586                          1.757                       2.276   \n",
      "587                          2.904                       2.987   \n",
      "588                          3.017                       2.969   \n",
      "\n",
      "     rh_transversetemporal_thickness  rh_insula_thickness  \\\n",
      "0                              3.361                3.458   \n",
      "1                              3.033                3.708   \n",
      "2                              2.199                3.382   \n",
      "3                              2.475                3.404   \n",
      "4                              1.854                2.841   \n",
      "..                               ...                  ...   \n",
      "584                            3.691                3.885   \n",
      "585                            2.611                3.871   \n",
      "586                            2.265                3.481   \n",
      "587                            3.003                3.207   \n",
      "588                            2.765                3.222   \n",
      "\n",
      "     rh_MeanThickness_thickness  ChildID2  \n",
      "0                       2.94654     50602  \n",
      "1                       3.04415     22301  \n",
      "2                       2.90963     93201  \n",
      "3                       2.87815    100302  \n",
      "4                       2.45279      9602  \n",
      "..                          ...       ...  \n",
      "584                     2.52185     18501  \n",
      "585                     2.43870     22302  \n",
      "586                     2.35131      6402  \n",
      "587                     2.81043     46401  \n",
      "588                     2.82831     22202  \n",
      "\n",
      "[589 rows x 171 columns]\n",
      "0 ChildID\n",
      "1 FamilyID\n",
      "2 GenderTwin\n",
      "3 C3.1_AgeMonths\n",
      "4 C3.3_AgeMonths\n",
      "5 C3.1_DNA_Zygosity\n",
      "6 C3.3_SRS_TotalScore_18\n",
      "7 EstimatedIQ\n",
      "8 SocioEconomicStatus\n",
      "9 C3.3_Stop_Total_CorrectGO\n",
      "10 C3.3_Stop_Total_CorrectNOGO\n",
      "11 C3.3_Stop_Total_Mean_corGO_RT\n",
      "12 visit\n",
      "13 AgeYears\n",
      "14 Left.Cerebellum.White.Matter\n",
      "15 Left.Cerebellum.Cortex\n",
      "16 Left.Thalamus.Proper\n",
      "17 Left.Caudate\n",
      "18 Left.Putamen\n",
      "19 Left.Pallidum\n",
      "20 Left.Hippocampus\n",
      "21 Left.Amygdala\n",
      "22 Left.Accumbens.area\n",
      "23 Right.Cerebellum.White.Matter\n",
      "24 Right.Cerebellum.Cortex\n",
      "25 Right.Thalamus.Proper\n",
      "26 Right.Caudate\n",
      "27 Right.Putamen\n",
      "28 Right.Pallidum\n",
      "29 Right.Hippocampus\n",
      "30 Right.Amygdala\n",
      "31 Right.Accumbens.area\n",
      "32 CC_Posterior\n",
      "33 CC_Mid_Posterior\n",
      "34 CC_Central\n",
      "35 CC_Mid_Anterior\n",
      "36 CC_Anterior\n",
      "37 lhCortexVol\n",
      "38 rhCortexVol\n",
      "39 CortexVol\n",
      "40 SubCortGrayVol\n",
      "41 TotalGrayVol\n",
      "42 lh_caudalanteriorcingulate_area\n",
      "43 lh_caudalmiddlefrontal_area\n",
      "44 lh_cuneus_area\n",
      "45 lh_entorhinal_area\n",
      "46 lh_fusiform_area\n",
      "47 lh_inferiorparietal_area\n",
      "48 lh_inferiortemporal_area\n",
      "49 lh_isthmuscingulate_area\n",
      "50 lh_lateraloccipital_area\n",
      "51 lh_lateralorbitofrontal_area\n",
      "52 lh_lingual_area\n",
      "53 lh_medialorbitofrontal_area\n",
      "54 lh_middletemporal_area\n",
      "55 lh_parahippocampal_area\n",
      "56 lh_paracentral_area\n",
      "57 lh_parsopercularis_area\n",
      "58 lh_parsorbitalis_area\n",
      "59 lh_parstriangularis_area\n",
      "60 lh_pericalcarine_area\n",
      "61 lh_postcentral_area\n",
      "62 lh_posteriorcingulate_area\n",
      "63 lh_precentral_area\n",
      "64 lh_precuneus_area\n",
      "65 lh_rostralanteriorcingulate_area\n",
      "66 lh_rostralmiddlefrontal_area\n",
      "67 lh_superiorfrontal_area\n",
      "68 lh_superiorparietal_area\n",
      "69 lh_superiortemporal_area\n",
      "70 lh_supramarginal_area\n",
      "71 lh_transversetemporal_area\n",
      "72 lh_insula_area\n",
      "73 lh_WhiteSurfArea_area\n",
      "74 rh_caudalanteriorcingulate_area\n",
      "75 rh_caudalmiddlefrontal_area\n",
      "76 rh_cuneus_area\n",
      "77 rh_entorhinal_area\n",
      "78 rh_fusiform_area\n",
      "79 rh_inferiorparietal_area\n",
      "80 rh_inferiortemporal_area\n",
      "81 rh_isthmuscingulate_area\n",
      "82 rh_lateraloccipital_area\n",
      "83 rh_lateralorbitofrontal_area\n",
      "84 rh_lingual_area\n",
      "85 rh_medialorbitofrontal_area\n",
      "86 rh_middletemporal_area\n",
      "87 rh_parahippocampal_area\n",
      "88 rh_paracentral_area\n",
      "89 rh_parsopercularis_area\n",
      "90 rh_parsorbitalis_area\n",
      "91 rh_parstriangularis_area\n",
      "92 rh_pericalcarine_area\n",
      "93 rh_postcentral_area\n",
      "94 rh_posteriorcingulate_area\n",
      "95 rh_precentral_area\n",
      "96 rh_precuneus_area\n",
      "97 rh_rostralanteriorcingulate_area\n",
      "98 rh_rostralmiddlefrontal_area\n",
      "99 rh_superiorfrontal_area\n",
      "100 rh_superiorparietal_area\n",
      "101 rh_superiortemporal_area\n",
      "102 rh_supramarginal_area\n",
      "103 rh_transversetemporal_area\n",
      "104 rh_insula_area\n",
      "105 rh_WhiteSurfArea_area\n",
      "106 lh_caudalanteriorcingulate_thickness\n",
      "107 lh_caudalmiddlefrontal_thickness\n",
      "108 lh_cuneus_thickness\n",
      "109 lh_entorhinal_thickness\n",
      "110 lh_fusiform_thickness\n",
      "111 lh_inferiorparietal_thickness\n",
      "112 lh_inferiortemporal_thickness\n",
      "113 lh_isthmuscingulate_thickness\n",
      "114 lh_lateraloccipital_thickness\n",
      "115 lh_lateralorbitofrontal_thickness\n",
      "116 lh_lingual_thickness\n",
      "117 lh_medialorbitofrontal_thickness\n",
      "118 lh_middletemporal_thickness\n",
      "119 lh_parahippocampal_thickness\n",
      "120 lh_paracentral_thickness\n",
      "121 lh_parsopercularis_thickness\n",
      "122 lh_parsorbitalis_thickness\n",
      "123 lh_parstriangularis_thickness\n",
      "124 lh_pericalcarine_thickness\n",
      "125 lh_postcentral_thickness\n",
      "126 lh_posteriorcingulate_thickness\n",
      "127 lh_precentral_thickness\n",
      "128 lh_precuneus_thickness\n",
      "129 lh_rostralanteriorcingulate_thickness\n",
      "130 lh_rostralmiddlefrontal_thickness\n",
      "131 lh_superiorfrontal_thickness\n",
      "132 lh_superiorparietal_thickness\n",
      "133 lh_superiortemporal_thickness\n",
      "134 lh_supramarginal_thickness\n",
      "135 lh_transversetemporal_thickness\n",
      "136 lh_insula_thickness\n",
      "137 lh_MeanThickness_thickness\n",
      "138 rh_caudalanteriorcingulate_thickness\n",
      "139 rh_caudalmiddlefrontal_thickness\n",
      "140 rh_cuneus_thickness\n",
      "141 rh_entorhinal_thickness\n",
      "142 rh_fusiform_thickness\n",
      "143 rh_inferiorparietal_thickness\n",
      "144 rh_inferiortemporal_thickness\n",
      "145 rh_isthmuscingulate_thickness\n",
      "146 rh_lateraloccipital_thickness\n",
      "147 rh_lateralorbitofrontal_thickness\n",
      "148 rh_lingual_thickness\n",
      "149 rh_medialorbitofrontal_thickness\n",
      "150 rh_middletemporal_thickness\n",
      "151 rh_parahippocampal_thickness\n",
      "152 rh_paracentral_thickness\n",
      "153 rh_parsopercularis_thickness\n",
      "154 rh_parsorbitalis_thickness\n",
      "155 rh_parstriangularis_thickness\n",
      "156 rh_pericalcarine_thickness\n",
      "157 rh_postcentral_thickness\n",
      "158 rh_posteriorcingulate_thickness\n",
      "159 rh_precentral_thickness\n",
      "160 rh_precuneus_thickness\n",
      "161 rh_rostralanteriorcingulate_thickness\n",
      "162 rh_rostralmiddlefrontal_thickness\n",
      "163 rh_superiorfrontal_thickness\n",
      "164 rh_superiorparietal_thickness\n",
      "165 rh_superiortemporal_thickness\n",
      "166 rh_supramarginal_thickness\n",
      "167 rh_transversetemporal_thickness\n",
      "168 rh_insula_thickness\n",
      "169 rh_MeanThickness_thickness\n",
      "170 ChildID2\n"
     ]
    }
   ],
   "source": [
    "# Remove brain measures that are not important\n",
    "unselected = [\"Left.Lateral.Ventricle\",\"Left.Inf.Lat.Vent\",\"X3rd.Ventricle\",\"X4th.Ventricle\",\"Brain.Stem\",\"CSF\",\"Left.VentralDC\",\"Left.vessel\",\"Left.choroid.plexus\",\"Right.Lateral.Ventricle\",\"Right.Inf.Lat.Vent\",\"Right.VentralDC\",\"Right.vessel\",\"Right.choroid.plexus\",\"X5th.Ventricle\",\"WM.hypointensities\",\"Optic.Chiasm\",\"BrainSegVol\",\"BrainSegVolNotVent\",\"BrainSegVolNotVentSurf\",\"MaskVol\",\"BrainSegVol.to.eTIV\",\"MaskVol.to.eTIV\",\"EstimatedTotalIntraCranialVol\",\"SupraTentorialVol\",\"SupraTentorialVolNotVent\",\"SupraTentorialVolNotVentVox\"]\n",
    "var_inc = [i for i in data.columns if i not in unselected]\n",
    "print(var_inc)\n",
    "data = data[var_inc]\n",
    "print(data)\n",
    "\n",
    "for i, col in enumerate(data.columns): \n",
    "    print(i,col)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChildID</th>\n",
       "      <th>FamilyID</th>\n",
       "      <th>GenderTwin</th>\n",
       "      <th>C3.1_AgeMonths</th>\n",
       "      <th>C3.3_AgeMonths</th>\n",
       "      <th>C3.1_DNA_Zygosity</th>\n",
       "      <th>C3.3_SRS_TotalScore_18</th>\n",
       "      <th>EstimatedIQ</th>\n",
       "      <th>SocioEconomicStatus</th>\n",
       "      <th>C3.3_Stop_Total_CorrectGO</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_rostralanteriorcingulate_thickness</th>\n",
       "      <th>rh_rostralmiddlefrontal_thickness</th>\n",
       "      <th>rh_superiorfrontal_thickness</th>\n",
       "      <th>rh_superiorparietal_thickness</th>\n",
       "      <th>rh_superiortemporal_thickness</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>ChildID2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>601</td>\n",
       "      <td>6</td>\n",
       "      <td>boys</td>\n",
       "      <td>89.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>high SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.894</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.253</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.209</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.361</td>\n",
       "      <td>3.458</td>\n",
       "      <td>2.94654</td>\n",
       "      <td>50602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>701</td>\n",
       "      <td>7</td>\n",
       "      <td>boys</td>\n",
       "      <td>89.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.815</td>\n",
       "      <td>2.899</td>\n",
       "      <td>3.446</td>\n",
       "      <td>2.881</td>\n",
       "      <td>3.325</td>\n",
       "      <td>3.192</td>\n",
       "      <td>3.033</td>\n",
       "      <td>3.708</td>\n",
       "      <td>3.04415</td>\n",
       "      <td>22301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>boys</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>92.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>4.122</td>\n",
       "      <td>2.822</td>\n",
       "      <td>3.407</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.960</td>\n",
       "      <td>2.976</td>\n",
       "      <td>2.199</td>\n",
       "      <td>3.382</td>\n",
       "      <td>2.90963</td>\n",
       "      <td>93201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>902</td>\n",
       "      <td>9</td>\n",
       "      <td>boys</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>96.710526</td>\n",
       "      <td>...</td>\n",
       "      <td>3.659</td>\n",
       "      <td>2.912</td>\n",
       "      <td>3.433</td>\n",
       "      <td>2.418</td>\n",
       "      <td>3.051</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.475</td>\n",
       "      <td>3.404</td>\n",
       "      <td>2.87815</td>\n",
       "      <td>100302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1301</td>\n",
       "      <td>13</td>\n",
       "      <td>boys</td>\n",
       "      <td>92.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.953</td>\n",
       "      <td>2.708</td>\n",
       "      <td>2.741</td>\n",
       "      <td>2.156</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.854</td>\n",
       "      <td>2.841</td>\n",
       "      <td>2.45279</td>\n",
       "      <td>9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>115702</td>\n",
       "      <td>1157</td>\n",
       "      <td>girls</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>6.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>83.552632</td>\n",
       "      <td>...</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.705</td>\n",
       "      <td>3.208</td>\n",
       "      <td>2.394</td>\n",
       "      <td>2.595</td>\n",
       "      <td>2.871</td>\n",
       "      <td>3.691</td>\n",
       "      <td>3.885</td>\n",
       "      <td>2.52185</td>\n",
       "      <td>18501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>116401</td>\n",
       "      <td>1164</td>\n",
       "      <td>girls</td>\n",
       "      <td>86.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>high SES</td>\n",
       "      <td>94.078947</td>\n",
       "      <td>...</td>\n",
       "      <td>2.494</td>\n",
       "      <td>2.717</td>\n",
       "      <td>2.921</td>\n",
       "      <td>2.456</td>\n",
       "      <td>1.783</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.611</td>\n",
       "      <td>3.871</td>\n",
       "      <td>2.43870</td>\n",
       "      <td>22302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>116402</td>\n",
       "      <td>1164</td>\n",
       "      <td>girls</td>\n",
       "      <td>86.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>high SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.612</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.125</td>\n",
       "      <td>2.064</td>\n",
       "      <td>1.757</td>\n",
       "      <td>2.276</td>\n",
       "      <td>2.265</td>\n",
       "      <td>3.481</td>\n",
       "      <td>2.35131</td>\n",
       "      <td>6402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>117401</td>\n",
       "      <td>1174</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>94.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>3.383</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.265</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2.904</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.207</td>\n",
       "      <td>2.81043</td>\n",
       "      <td>46401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>117402</td>\n",
       "      <td>1174</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>98.684211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.408</td>\n",
       "      <td>2.751</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.608</td>\n",
       "      <td>3.017</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.765</td>\n",
       "      <td>3.222</td>\n",
       "      <td>2.82831</td>\n",
       "      <td>22202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChildID  FamilyID GenderTwin  C3.1_AgeMonths  C3.3_AgeMonths  \\\n",
       "0        601         6       boys            89.0           114.0   \n",
       "1        701         7       boys            89.0           113.0   \n",
       "2        901         9       boys            87.0           111.0   \n",
       "3        902         9       boys            87.0           111.0   \n",
       "4       1301        13       boys            92.0           116.0   \n",
       "..       ...       ...        ...             ...             ...   \n",
       "584   115702      1157      girls            87.0           111.0   \n",
       "585   116401      1164      girls            86.0           109.0   \n",
       "586   116402      1164      girls            86.0           109.0   \n",
       "587   117401      1174      girls             NaN           137.0   \n",
       "588   117402      1174      girls             NaN           137.0   \n",
       "\n",
       "    C3.1_DNA_Zygosity  C3.3_SRS_TotalScore_18  EstimatedIQ  \\\n",
       "0                  DZ                     2.0         87.5   \n",
       "1                  DZ                     NaN         97.5   \n",
       "2                  MZ                     2.0         97.5   \n",
       "3                  MZ                     3.0         95.0   \n",
       "4                  MZ                     2.0         82.5   \n",
       "..                ...                     ...          ...   \n",
       "584                DZ                     6.0         97.5   \n",
       "585                MZ                    11.0         82.5   \n",
       "586                MZ                     8.0        100.0   \n",
       "587               NaN                     6.0          NaN   \n",
       "588               NaN                     7.0          NaN   \n",
       "\n",
       "    SocioEconomicStatus  C3.3_Stop_Total_CorrectGO  ...  \\\n",
       "0              high SES                  99.342105  ...   \n",
       "1            middle SES                  99.342105  ...   \n",
       "2            middle SES                  92.105263  ...   \n",
       "3            middle SES                  96.710526  ...   \n",
       "4            middle SES                  99.342105  ...   \n",
       "..                  ...                        ...  ...   \n",
       "584          middle SES                  83.552632  ...   \n",
       "585            high SES                  94.078947  ...   \n",
       "586            high SES                  99.342105  ...   \n",
       "587          middle SES                  94.736842  ...   \n",
       "588          middle SES                  98.684211  ...   \n",
       "\n",
       "     rh_rostralanteriorcingulate_thickness  rh_rostralmiddlefrontal_thickness  \\\n",
       "0                                    3.894                              2.957   \n",
       "1                                    3.815                              2.899   \n",
       "2                                    4.122                              2.822   \n",
       "3                                    3.659                              2.912   \n",
       "4                                    2.953                              2.708   \n",
       "..                                     ...                                ...   \n",
       "584                                  2.533                              2.705   \n",
       "585                                  2.494                              2.717   \n",
       "586                                  2.612                              2.809   \n",
       "587                                  3.383                              2.964   \n",
       "588                                  3.408                              2.751   \n",
       "\n",
       "     rh_superiorfrontal_thickness  rh_superiorparietal_thickness  \\\n",
       "0                           3.253                          2.828   \n",
       "1                           3.446                          2.881   \n",
       "2                           3.407                          2.614   \n",
       "3                           3.433                          2.418   \n",
       "4                           2.741                          2.156   \n",
       "..                            ...                            ...   \n",
       "584                         3.208                          2.394   \n",
       "585                         2.921                          2.456   \n",
       "586                         3.125                          2.064   \n",
       "587                         3.265                          2.588   \n",
       "588                         3.361                          2.608   \n",
       "\n",
       "     rh_superiortemporal_thickness  rh_supramarginal_thickness  \\\n",
       "0                            3.209                       3.008   \n",
       "1                            3.325                       3.192   \n",
       "2                            2.960                       2.976   \n",
       "3                            3.051                       2.969   \n",
       "4                            2.129                       2.026   \n",
       "..                             ...                         ...   \n",
       "584                          2.595                       2.871   \n",
       "585                          1.783                       2.833   \n",
       "586                          1.757                       2.276   \n",
       "587                          2.904                       2.987   \n",
       "588                          3.017                       2.969   \n",
       "\n",
       "     rh_transversetemporal_thickness  rh_insula_thickness  \\\n",
       "0                              3.361                3.458   \n",
       "1                              3.033                3.708   \n",
       "2                              2.199                3.382   \n",
       "3                              2.475                3.404   \n",
       "4                              1.854                2.841   \n",
       "..                               ...                  ...   \n",
       "584                            3.691                3.885   \n",
       "585                            2.611                3.871   \n",
       "586                            2.265                3.481   \n",
       "587                            3.003                3.207   \n",
       "588                            2.765                3.222   \n",
       "\n",
       "     rh_MeanThickness_thickness  ChildID2  \n",
       "0                       2.94654     50602  \n",
       "1                       3.04415     22301  \n",
       "2                       2.90963     93201  \n",
       "3                       2.87815    100302  \n",
       "4                       2.45279      9602  \n",
       "..                          ...       ...  \n",
       "584                     2.52185     18501  \n",
       "585                     2.43870     22302  \n",
       "586                     2.35131      6402  \n",
       "587                     2.81043     46401  \n",
       "588                     2.82831     22202  \n",
       "\n",
       "[589 rows x 171 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,\n",
       "        95.,  96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105.,\n",
       "       106., 107., 108., 109., 110., 111., 112., 113., 114., 115., 116.,\n",
       "       117., 118., 119., 120., 121., 122., 123., 124., 125., 126., 127.,\n",
       "       128., 129., 130., 131., 132., 133., 134., 137., 140.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(data['AgeYears'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data['AgeYears'],bins=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChildID</th>\n",
       "      <th>FamilyID</th>\n",
       "      <th>GenderTwin</th>\n",
       "      <th>C3.1_AgeMonths</th>\n",
       "      <th>C3.3_AgeMonths</th>\n",
       "      <th>C3.1_DNA_Zygosity</th>\n",
       "      <th>C3.3_SRS_TotalScore_18</th>\n",
       "      <th>EstimatedIQ</th>\n",
       "      <th>SocioEconomicStatus</th>\n",
       "      <th>C3.3_Stop_Total_CorrectGO</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_rostralanteriorcingulate_thickness</th>\n",
       "      <th>rh_rostralmiddlefrontal_thickness</th>\n",
       "      <th>rh_superiorfrontal_thickness</th>\n",
       "      <th>rh_superiorparietal_thickness</th>\n",
       "      <th>rh_superiortemporal_thickness</th>\n",
       "      <th>rh_supramarginal_thickness</th>\n",
       "      <th>rh_transversetemporal_thickness</th>\n",
       "      <th>rh_insula_thickness</th>\n",
       "      <th>rh_MeanThickness_thickness</th>\n",
       "      <th>ChildID2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>601</td>\n",
       "      <td>6</td>\n",
       "      <td>boys</td>\n",
       "      <td>89.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87.5</td>\n",
       "      <td>high SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.894</td>\n",
       "      <td>2.957</td>\n",
       "      <td>3.253</td>\n",
       "      <td>2.828</td>\n",
       "      <td>3.209</td>\n",
       "      <td>3.008</td>\n",
       "      <td>3.361</td>\n",
       "      <td>3.458</td>\n",
       "      <td>2.94654</td>\n",
       "      <td>50602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>701</td>\n",
       "      <td>7</td>\n",
       "      <td>boys</td>\n",
       "      <td>89.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>3.815</td>\n",
       "      <td>2.899</td>\n",
       "      <td>3.446</td>\n",
       "      <td>2.881</td>\n",
       "      <td>3.325</td>\n",
       "      <td>3.192</td>\n",
       "      <td>3.033</td>\n",
       "      <td>3.708</td>\n",
       "      <td>3.04415</td>\n",
       "      <td>22301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>901</td>\n",
       "      <td>9</td>\n",
       "      <td>boys</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>92.105263</td>\n",
       "      <td>...</td>\n",
       "      <td>4.122</td>\n",
       "      <td>2.822</td>\n",
       "      <td>3.407</td>\n",
       "      <td>2.614</td>\n",
       "      <td>2.960</td>\n",
       "      <td>2.976</td>\n",
       "      <td>2.199</td>\n",
       "      <td>3.382</td>\n",
       "      <td>2.90963</td>\n",
       "      <td>93201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>902</td>\n",
       "      <td>9</td>\n",
       "      <td>boys</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>96.710526</td>\n",
       "      <td>...</td>\n",
       "      <td>3.659</td>\n",
       "      <td>2.912</td>\n",
       "      <td>3.433</td>\n",
       "      <td>2.418</td>\n",
       "      <td>3.051</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.475</td>\n",
       "      <td>3.404</td>\n",
       "      <td>2.87815</td>\n",
       "      <td>100302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1301</td>\n",
       "      <td>13</td>\n",
       "      <td>boys</td>\n",
       "      <td>92.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.953</td>\n",
       "      <td>2.708</td>\n",
       "      <td>2.741</td>\n",
       "      <td>2.156</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.854</td>\n",
       "      <td>2.841</td>\n",
       "      <td>2.45279</td>\n",
       "      <td>9602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>115702</td>\n",
       "      <td>1157</td>\n",
       "      <td>girls</td>\n",
       "      <td>87.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>DZ</td>\n",
       "      <td>6.0</td>\n",
       "      <td>97.5</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>83.552632</td>\n",
       "      <td>...</td>\n",
       "      <td>2.533</td>\n",
       "      <td>2.705</td>\n",
       "      <td>3.208</td>\n",
       "      <td>2.394</td>\n",
       "      <td>2.595</td>\n",
       "      <td>2.871</td>\n",
       "      <td>3.691</td>\n",
       "      <td>3.885</td>\n",
       "      <td>2.52185</td>\n",
       "      <td>18501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>116401</td>\n",
       "      <td>1164</td>\n",
       "      <td>girls</td>\n",
       "      <td>86.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>high SES</td>\n",
       "      <td>94.078947</td>\n",
       "      <td>...</td>\n",
       "      <td>2.494</td>\n",
       "      <td>2.717</td>\n",
       "      <td>2.921</td>\n",
       "      <td>2.456</td>\n",
       "      <td>1.783</td>\n",
       "      <td>2.833</td>\n",
       "      <td>2.611</td>\n",
       "      <td>3.871</td>\n",
       "      <td>2.43870</td>\n",
       "      <td>22302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>116402</td>\n",
       "      <td>1164</td>\n",
       "      <td>girls</td>\n",
       "      <td>86.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>MZ</td>\n",
       "      <td>8.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>high SES</td>\n",
       "      <td>99.342105</td>\n",
       "      <td>...</td>\n",
       "      <td>2.612</td>\n",
       "      <td>2.809</td>\n",
       "      <td>3.125</td>\n",
       "      <td>2.064</td>\n",
       "      <td>1.757</td>\n",
       "      <td>2.276</td>\n",
       "      <td>2.265</td>\n",
       "      <td>3.481</td>\n",
       "      <td>2.35131</td>\n",
       "      <td>6402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>117401</td>\n",
       "      <td>1174</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>94.736842</td>\n",
       "      <td>...</td>\n",
       "      <td>3.383</td>\n",
       "      <td>2.964</td>\n",
       "      <td>3.265</td>\n",
       "      <td>2.588</td>\n",
       "      <td>2.904</td>\n",
       "      <td>2.987</td>\n",
       "      <td>3.003</td>\n",
       "      <td>3.207</td>\n",
       "      <td>2.81043</td>\n",
       "      <td>46401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>117402</td>\n",
       "      <td>1174</td>\n",
       "      <td>girls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>middle SES</td>\n",
       "      <td>98.684211</td>\n",
       "      <td>...</td>\n",
       "      <td>3.408</td>\n",
       "      <td>2.751</td>\n",
       "      <td>3.361</td>\n",
       "      <td>2.608</td>\n",
       "      <td>3.017</td>\n",
       "      <td>2.969</td>\n",
       "      <td>2.765</td>\n",
       "      <td>3.222</td>\n",
       "      <td>2.82831</td>\n",
       "      <td>22202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ChildID  FamilyID GenderTwin  C3.1_AgeMonths  C3.3_AgeMonths  \\\n",
       "0        601         6       boys            89.0           114.0   \n",
       "1        701         7       boys            89.0           113.0   \n",
       "2        901         9       boys            87.0           111.0   \n",
       "3        902         9       boys            87.0           111.0   \n",
       "4       1301        13       boys            92.0           116.0   \n",
       "..       ...       ...        ...             ...             ...   \n",
       "584   115702      1157      girls            87.0           111.0   \n",
       "585   116401      1164      girls            86.0           109.0   \n",
       "586   116402      1164      girls            86.0           109.0   \n",
       "587   117401      1174      girls             NaN           137.0   \n",
       "588   117402      1174      girls             NaN           137.0   \n",
       "\n",
       "    C3.1_DNA_Zygosity  C3.3_SRS_TotalScore_18  EstimatedIQ  \\\n",
       "0                  DZ                     2.0         87.5   \n",
       "1                  DZ                     NaN         97.5   \n",
       "2                  MZ                     2.0         97.5   \n",
       "3                  MZ                     3.0         95.0   \n",
       "4                  MZ                     2.0         82.5   \n",
       "..                ...                     ...          ...   \n",
       "584                DZ                     6.0         97.5   \n",
       "585                MZ                    11.0         82.5   \n",
       "586                MZ                     8.0        100.0   \n",
       "587               NaN                     6.0          NaN   \n",
       "588               NaN                     7.0          NaN   \n",
       "\n",
       "    SocioEconomicStatus  C3.3_Stop_Total_CorrectGO  ...  \\\n",
       "0              high SES                  99.342105  ...   \n",
       "1            middle SES                  99.342105  ...   \n",
       "2            middle SES                  92.105263  ...   \n",
       "3            middle SES                  96.710526  ...   \n",
       "4            middle SES                  99.342105  ...   \n",
       "..                  ...                        ...  ...   \n",
       "584          middle SES                  83.552632  ...   \n",
       "585            high SES                  94.078947  ...   \n",
       "586            high SES                  99.342105  ...   \n",
       "587          middle SES                  94.736842  ...   \n",
       "588          middle SES                  98.684211  ...   \n",
       "\n",
       "     rh_rostralanteriorcingulate_thickness  rh_rostralmiddlefrontal_thickness  \\\n",
       "0                                    3.894                              2.957   \n",
       "1                                    3.815                              2.899   \n",
       "2                                    4.122                              2.822   \n",
       "3                                    3.659                              2.912   \n",
       "4                                    2.953                              2.708   \n",
       "..                                     ...                                ...   \n",
       "584                                  2.533                              2.705   \n",
       "585                                  2.494                              2.717   \n",
       "586                                  2.612                              2.809   \n",
       "587                                  3.383                              2.964   \n",
       "588                                  3.408                              2.751   \n",
       "\n",
       "     rh_superiorfrontal_thickness  rh_superiorparietal_thickness  \\\n",
       "0                           3.253                          2.828   \n",
       "1                           3.446                          2.881   \n",
       "2                           3.407                          2.614   \n",
       "3                           3.433                          2.418   \n",
       "4                           2.741                          2.156   \n",
       "..                            ...                            ...   \n",
       "584                         3.208                          2.394   \n",
       "585                         2.921                          2.456   \n",
       "586                         3.125                          2.064   \n",
       "587                         3.265                          2.588   \n",
       "588                         3.361                          2.608   \n",
       "\n",
       "     rh_superiortemporal_thickness  rh_supramarginal_thickness  \\\n",
       "0                            3.209                       3.008   \n",
       "1                            3.325                       3.192   \n",
       "2                            2.960                       2.976   \n",
       "3                            3.051                       2.969   \n",
       "4                            2.129                       2.026   \n",
       "..                             ...                         ...   \n",
       "584                          2.595                       2.871   \n",
       "585                          1.783                       2.833   \n",
       "586                          1.757                       2.276   \n",
       "587                          2.904                       2.987   \n",
       "588                          3.017                       2.969   \n",
       "\n",
       "     rh_transversetemporal_thickness  rh_insula_thickness  \\\n",
       "0                              3.361                3.458   \n",
       "1                              3.033                3.708   \n",
       "2                              2.199                3.382   \n",
       "3                              2.475                3.404   \n",
       "4                              1.854                2.841   \n",
       "..                               ...                  ...   \n",
       "584                            3.691                3.885   \n",
       "585                            2.611                3.871   \n",
       "586                            2.265                3.481   \n",
       "587                            3.003                3.207   \n",
       "588                            2.765                3.222   \n",
       "\n",
       "     rh_MeanThickness_thickness  ChildID2  \n",
       "0                       2.94654     50602  \n",
       "1                       3.04415     22301  \n",
       "2                       2.90963     93201  \n",
       "3                       2.87815    100302  \n",
       "4                       2.45279      9602  \n",
       "..                          ...       ...  \n",
       "584                     2.52185     18501  \n",
       "585                     2.43870     22302  \n",
       "586                     2.35131      6402  \n",
       "587                     2.81043     46401  \n",
       "588                     2.82831     22202  \n",
       "\n",
       "[589 rows x 198 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run PCA analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we used the whole dataset to find components using PCA because it is a separate question from the SRS prediction model\n",
    "# this result will be fed into the prediction model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "brainfeatures = data.columns[15:197] # Separating out the features\n",
    "x = data.loc[:, brainfeatures].values # Separating out the target\n",
    "y = data.loc[:,['C3.3_SRS_TotalScore_18']].values # Standardizing the features\n",
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.25659393  7.14420061  1.02877477 ...  1.21388757 -0.49088137\n",
      "   0.17835392]\n",
      " [-6.76912225  2.82688833  1.60038047 ...  1.64301852  1.2785459\n",
      "   0.49469436]\n",
      " [-6.58966148 -1.41856139  2.30585043 ... -0.93045261 -0.40348967\n",
      "  -0.78970591]\n",
      " ...\n",
      " [11.90994959 -4.56460853  1.78127333 ... -1.25527915  0.33031573\n",
      "  -2.1682104 ]\n",
      " [ 3.16714161  5.35045174 -2.60787585 ...  0.41063322 -0.94134362\n",
      "  -0.03033443]\n",
      " [ 2.7316859   5.00357555 -2.41846547 ... -0.63829808 -1.2136543\n",
      "   0.44280287]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=25)\n",
    "principalComponents = pca.fit_transform(x)\n",
    "print(principalComponents)\n",
    "#principalDf = pd.DataFrame(data = principalComponents\n",
    " #            , columns = ['principal component 1', 'principal component 2'])\n",
    "principalComponents.shape\n",
    "principalData = pd.DataFrame(data = principalComponents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge data back to Demographics\n",
    "finalData = pd.concat([principalData, data[['AgeYears','GenderTwin']]], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select train data HC only\n",
    "# Make test and train dataset that is balanced for SRS score, gender, and have same family members together\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_srs = data[np.isfinite(data['C3.3_SRS_TotalScore_18'])].copy()\n",
    "#print(X_srs)\n",
    "X_srs = X_srs[X_srs['visit'] == 1].copy()# select data of time point 1 only \n",
    "\n",
    "#len(X_srs)\n",
    "\n",
    "# We want same family members together in test or train\n",
    "X = X_srs.drop_duplicates(subset = 'FamilyID').copy()\n",
    "\n",
    "# make a binary value for SRS, so the train and test data will be balanced\n",
    "X['SRS_binary'] = X['C3.3_SRS_TotalScore_18'] > 7\n",
    "\n",
    "# select data from low SRS scores only = HC\n",
    "X_TD = X[X['SRS_binary'] == False] # Typical development\n",
    "X_AD = X[X['SRS_binary'] == True] # Atypical development\n",
    "\n",
    "#y = X[['GenderTwin', 'SRS_binary']] # make variable for the categories that youd like to balance\n",
    "y = X_TD[['GenderTwin']] # make variable for the categories that youd like to balance\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_TD, y, test_size=0.33, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 156)\n",
      "(96, 1)\n"
     ]
    }
   ],
   "source": [
    "# merge high SRS (Atypical Development) to test set including typical development\n",
    "X_test = X_test.append(X_AD)\n",
    "\n",
    "# merge for y_test data\n",
    "y_test_AD = X_AD[['GenderTwin']]\n",
    "y_test = y_test.append(y_test_AD)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match family id's selceted with X_train and match to full set X_srs\n",
    "arraytrain=X_train.loc[:, 'FamilyID'].tolist()\n",
    "len(arraytrain)\n",
    "# selecting rows based on condition\n",
    "X_srs_train = X_srs[X_srs['FamilyID'].isin(arraytrain)]\n",
    "\n",
    "# Select brain data and scale\n",
    "brainfeatures = X_srs_train.columns[15:197] # Separating out the features\n",
    "X_srs_brain_train = X_srs_train.loc[:, brainfeatures].values # Separating out the target\n",
    "X_srs_brain_train = StandardScaler().fit_transform(X_srs_brain_train)\n",
    "\n",
    "X_srs_brain_train_Df = pd.DataFrame(data = X_srs_brain_train)\n",
    "\n",
    "print(X_srs_brain_train_Df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match family id's selceted with X_test and match to full set X_srs\n",
    "arraytest=X_test.loc[:, 'FamilyID'].tolist()\n",
    "arraytest\n",
    "# selecting rows based on condition\n",
    "X_srs_test = X_srs[X_srs['FamilyID'].isin(arraytest)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first devide X_srs_brain_train in a train and validating dataset\n",
    "    \n",
    "X_train, X_val = train_test_split(X_srs_brain_train, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 48 samples\n",
      "Epoch 1/500\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 1.1305 - val_loss: 1.0749\n",
      "Epoch 2/500\n",
      "112/112 [==============================] - 0s 178us/sample - loss: 1.0860 - val_loss: 1.0512\n",
      "Epoch 3/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 1.0586 - val_loss: 1.0361\n",
      "Epoch 4/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 1.0396 - val_loss: 1.0249\n",
      "Epoch 5/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 1.0230 - val_loss: 1.0146\n",
      "Epoch 6/500\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 1.0081 - val_loss: 1.0035\n",
      "Epoch 7/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.9932 - val_loss: 0.9906\n",
      "Epoch 8/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.9783 - val_loss: 0.9757\n",
      "Epoch 9/500\n",
      "112/112 [==============================] - 0s 103us/sample - loss: 0.9614 - val_loss: 0.9593\n",
      "Epoch 10/500\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.9442 - val_loss: 0.9415\n",
      "Epoch 11/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.9261 - val_loss: 0.9224\n",
      "Epoch 12/500\n",
      "112/112 [==============================] - 0s 104us/sample - loss: 0.9067 - val_loss: 0.9024\n",
      "Epoch 13/500\n",
      "112/112 [==============================] - 0s 105us/sample - loss: 0.8851 - val_loss: 0.8813\n",
      "Epoch 14/500\n",
      "112/112 [==============================] - 0s 187us/sample - loss: 0.8635 - val_loss: 0.8597\n",
      "Epoch 15/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.8402 - val_loss: 0.8376\n",
      "Epoch 16/500\n",
      "112/112 [==============================] - 0s 101us/sample - loss: 0.8173 - val_loss: 0.8152\n",
      "Epoch 17/500\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.7932 - val_loss: 0.7932\n",
      "Epoch 18/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.7713 - val_loss: 0.7723\n",
      "Epoch 19/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.7483 - val_loss: 0.7528\n",
      "Epoch 20/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.7270 - val_loss: 0.7345\n",
      "Epoch 21/500\n",
      "112/112 [==============================] - 0s 163us/sample - loss: 0.7059 - val_loss: 0.7173\n",
      "Epoch 22/500\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.6873 - val_loss: 0.7013\n",
      "Epoch 23/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.6690 - val_loss: 0.6865\n",
      "Epoch 24/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.6515 - val_loss: 0.6723\n",
      "Epoch 25/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.6362 - val_loss: 0.6591\n",
      "Epoch 26/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.6209 - val_loss: 0.6477\n",
      "Epoch 27/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.6067 - val_loss: 0.6376\n",
      "Epoch 28/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.5935 - val_loss: 0.6288\n",
      "Epoch 29/500\n",
      "112/112 [==============================] - 0s 184us/sample - loss: 0.5814 - val_loss: 0.6210\n",
      "Epoch 30/500\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.5697 - val_loss: 0.6139\n",
      "Epoch 31/500\n",
      "112/112 [==============================] - 0s 174us/sample - loss: 0.5588 - val_loss: 0.6079\n",
      "Epoch 32/500\n",
      "112/112 [==============================] - 0s 112us/sample - loss: 0.5496 - val_loss: 0.6023\n",
      "Epoch 33/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.5409 - val_loss: 0.5972\n",
      "Epoch 34/500\n",
      "112/112 [==============================] - 0s 197us/sample - loss: 0.5331 - val_loss: 0.5925\n",
      "Epoch 35/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.5251 - val_loss: 0.5882\n",
      "Epoch 36/500\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.5186 - val_loss: 0.5846\n",
      "Epoch 37/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.5119 - val_loss: 0.5814\n",
      "Epoch 38/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.5060 - val_loss: 0.5783\n",
      "Epoch 39/500\n",
      "112/112 [==============================] - 0s 195us/sample - loss: 0.5005 - val_loss: 0.5757\n",
      "Epoch 40/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.4948 - val_loss: 0.5738\n",
      "Epoch 41/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.4899 - val_loss: 0.5714\n",
      "Epoch 42/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.4856 - val_loss: 0.5689\n",
      "Epoch 43/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.4810 - val_loss: 0.5662\n",
      "Epoch 44/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.4773 - val_loss: 0.5639\n",
      "Epoch 45/500\n",
      "112/112 [==============================] - 0s 173us/sample - loss: 0.4734 - val_loss: 0.5617\n",
      "Epoch 46/500\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.4700 - val_loss: 0.5596\n",
      "Epoch 47/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.4669 - val_loss: 0.5580\n",
      "Epoch 48/500\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.4637 - val_loss: 0.5564\n",
      "Epoch 49/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.4607 - val_loss: 0.5552\n",
      "Epoch 50/500\n",
      "112/112 [==============================] - 0s 171us/sample - loss: 0.4580 - val_loss: 0.5543\n",
      "Epoch 51/500\n",
      "112/112 [==============================] - 0s 215us/sample - loss: 0.4555 - val_loss: 0.5528\n",
      "Epoch 52/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.4529 - val_loss: 0.5510\n",
      "Epoch 53/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.4506 - val_loss: 0.5492\n",
      "Epoch 54/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.4482 - val_loss: 0.5473\n",
      "Epoch 55/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.4459 - val_loss: 0.5458\n",
      "Epoch 56/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.4439 - val_loss: 0.5446\n",
      "Epoch 57/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.4417 - val_loss: 0.5431\n",
      "Epoch 58/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.4399 - val_loss: 0.5415\n",
      "Epoch 59/500\n",
      "112/112 [==============================] - 0s 227us/sample - loss: 0.4381 - val_loss: 0.5398\n",
      "Epoch 60/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.4364 - val_loss: 0.5384\n",
      "Epoch 61/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.4347 - val_loss: 0.5376\n",
      "Epoch 62/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.4331 - val_loss: 0.5370\n",
      "Epoch 63/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.4316 - val_loss: 0.5361\n",
      "Epoch 64/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.4301 - val_loss: 0.5352\n",
      "Epoch 65/500\n",
      "112/112 [==============================] - 0s 228us/sample - loss: 0.4285 - val_loss: 0.5343\n",
      "Epoch 66/500\n",
      "112/112 [==============================] - 0s 232us/sample - loss: 0.4270 - val_loss: 0.5336\n",
      "Epoch 67/500\n",
      "112/112 [==============================] - 0s 200us/sample - loss: 0.4258 - val_loss: 0.5327\n",
      "Epoch 68/500\n",
      "112/112 [==============================] - 0s 196us/sample - loss: 0.4247 - val_loss: 0.5315\n",
      "Epoch 69/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.4233 - val_loss: 0.5303\n",
      "Epoch 70/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.4220 - val_loss: 0.5291\n",
      "Epoch 71/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.4208 - val_loss: 0.5281\n",
      "Epoch 72/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.4195 - val_loss: 0.5273\n",
      "Epoch 73/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.4182 - val_loss: 0.5267\n",
      "Epoch 74/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.4172 - val_loss: 0.5260\n",
      "Epoch 75/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.4158 - val_loss: 0.5254\n",
      "Epoch 76/500\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.4146 - val_loss: 0.5248\n",
      "Epoch 77/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.4134 - val_loss: 0.5242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "112/112 [==============================] - 0s 177us/sample - loss: 0.4121 - val_loss: 0.5239\n",
      "Epoch 79/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.4108 - val_loss: 0.5235\n",
      "Epoch 80/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.4097 - val_loss: 0.5231\n",
      "Epoch 81/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.4084 - val_loss: 0.5225\n",
      "Epoch 82/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.4073 - val_loss: 0.5218\n",
      "Epoch 83/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.4064 - val_loss: 0.5210\n",
      "Epoch 84/500\n",
      "112/112 [==============================] - 0s 112us/sample - loss: 0.4052 - val_loss: 0.5203\n",
      "Epoch 85/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.4041 - val_loss: 0.5197\n",
      "Epoch 86/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.4033 - val_loss: 0.5192\n",
      "Epoch 87/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.4021 - val_loss: 0.5186\n",
      "Epoch 88/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.4009 - val_loss: 0.5181\n",
      "Epoch 89/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.3999 - val_loss: 0.5176\n",
      "Epoch 90/500\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.3988 - val_loss: 0.5173\n",
      "Epoch 91/500\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3975 - val_loss: 0.5166\n",
      "Epoch 92/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.3965 - val_loss: 0.5157\n",
      "Epoch 93/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.3954 - val_loss: 0.5148\n",
      "Epoch 94/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.3943 - val_loss: 0.5140\n",
      "Epoch 95/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.3933 - val_loss: 0.5133\n",
      "Epoch 96/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.3923 - val_loss: 0.5128\n",
      "Epoch 97/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.3915 - val_loss: 0.5124\n",
      "Epoch 98/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.3903 - val_loss: 0.5118\n",
      "Epoch 99/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.3894 - val_loss: 0.5112\n",
      "Epoch 100/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.3883 - val_loss: 0.5102\n",
      "Epoch 101/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.3872 - val_loss: 0.5092\n",
      "Epoch 102/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3861 - val_loss: 0.5081\n",
      "Epoch 103/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.3852 - val_loss: 0.5074\n",
      "Epoch 104/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.3842 - val_loss: 0.5069\n",
      "Epoch 105/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.3831 - val_loss: 0.5064\n",
      "Epoch 106/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.3822 - val_loss: 0.5061\n",
      "Epoch 107/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.3811 - val_loss: 0.5059\n",
      "Epoch 108/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.3803 - val_loss: 0.5058\n",
      "Epoch 109/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.3794 - val_loss: 0.5055\n",
      "Epoch 110/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.3785 - val_loss: 0.5049\n",
      "Epoch 111/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.3772 - val_loss: 0.5045\n",
      "Epoch 112/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.3763 - val_loss: 0.5044\n",
      "Epoch 113/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.3754 - val_loss: 0.5043\n",
      "Epoch 114/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.3744 - val_loss: 0.5040\n",
      "Epoch 115/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.3736 - val_loss: 0.5035\n",
      "Epoch 116/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.3728 - val_loss: 0.5027\n",
      "Epoch 117/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.3720 - val_loss: 0.5019\n",
      "Epoch 118/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.3710 - val_loss: 0.5015\n",
      "Epoch 119/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.3700 - val_loss: 0.5013\n",
      "Epoch 120/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.3688 - val_loss: 0.5012\n",
      "Epoch 121/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.3680 - val_loss: 0.5009\n",
      "Epoch 122/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.3672 - val_loss: 0.5000\n",
      "Epoch 123/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.3663 - val_loss: 0.4988\n",
      "Epoch 124/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.3656 - val_loss: 0.4978\n",
      "Epoch 125/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.3646 - val_loss: 0.4970\n",
      "Epoch 126/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.3638 - val_loss: 0.4963\n",
      "Epoch 127/500\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3630 - val_loss: 0.4958\n",
      "Epoch 128/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.3622 - val_loss: 0.4955\n",
      "Epoch 129/500\n",
      "112/112 [==============================] - 0s 157us/sample - loss: 0.3614 - val_loss: 0.4950\n",
      "Epoch 130/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.3605 - val_loss: 0.4947\n",
      "Epoch 131/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.3597 - val_loss: 0.4942\n",
      "Epoch 132/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.3590 - val_loss: 0.4939\n",
      "Epoch 133/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.3582 - val_loss: 0.4936\n",
      "Epoch 134/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.3574 - val_loss: 0.4935\n",
      "Epoch 135/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.3566 - val_loss: 0.4933\n",
      "Epoch 136/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.3558 - val_loss: 0.4931\n",
      "Epoch 137/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.3550 - val_loss: 0.4929\n",
      "Epoch 138/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.3542 - val_loss: 0.4929\n",
      "Epoch 139/500\n",
      "112/112 [==============================] - 0s 103us/sample - loss: 0.3536 - val_loss: 0.4929\n",
      "Epoch 140/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.3528 - val_loss: 0.4925\n",
      "Epoch 141/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.3522 - val_loss: 0.4917\n",
      "Epoch 142/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.3513 - val_loss: 0.4908\n",
      "Epoch 143/500\n",
      "112/112 [==============================] - 0s 103us/sample - loss: 0.3505 - val_loss: 0.4902\n",
      "Epoch 144/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.3496 - val_loss: 0.4898\n",
      "Epoch 145/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.3488 - val_loss: 0.4894\n",
      "Epoch 146/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.3479 - val_loss: 0.4892\n",
      "Epoch 147/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.3472 - val_loss: 0.4891\n",
      "Epoch 148/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.3464 - val_loss: 0.4889\n",
      "Epoch 149/500\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.3457 - val_loss: 0.4889\n",
      "Epoch 150/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.3449 - val_loss: 0.4890\n",
      "Epoch 151/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.3442 - val_loss: 0.4888\n",
      "Epoch 152/500\n",
      "112/112 [==============================] - 0s 166us/sample - loss: 0.3435 - val_loss: 0.4885\n",
      "Epoch 153/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.3428 - val_loss: 0.4882\n",
      "Epoch 154/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3422 - val_loss: 0.4877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.3415 - val_loss: 0.4873\n",
      "Epoch 156/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.3408 - val_loss: 0.4872\n",
      "Epoch 157/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.3401 - val_loss: 0.4872\n",
      "Epoch 158/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.3395 - val_loss: 0.4870\n",
      "Epoch 159/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3387 - val_loss: 0.4864\n",
      "Epoch 160/500\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3380 - val_loss: 0.4860\n",
      "Epoch 161/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.3374 - val_loss: 0.4858\n",
      "Epoch 162/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.3367 - val_loss: 0.4859\n",
      "Epoch 163/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3361 - val_loss: 0.4857\n",
      "Epoch 164/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.3356 - val_loss: 0.4856\n",
      "Epoch 165/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.3350 - val_loss: 0.4852\n",
      "Epoch 166/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.3344 - val_loss: 0.4848\n",
      "Epoch 167/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3338 - val_loss: 0.4845\n",
      "Epoch 168/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.3332 - val_loss: 0.4841\n",
      "Epoch 169/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.3325 - val_loss: 0.4837\n",
      "Epoch 170/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3318 - val_loss: 0.4833\n",
      "Epoch 171/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3311 - val_loss: 0.4829\n",
      "Epoch 172/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.3305 - val_loss: 0.4826\n",
      "Epoch 173/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.3298 - val_loss: 0.4823\n",
      "Epoch 174/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.3292 - val_loss: 0.4820\n",
      "Epoch 175/500\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.3285 - val_loss: 0.4817\n",
      "Epoch 176/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.3279 - val_loss: 0.4816\n",
      "Epoch 177/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.3273 - val_loss: 0.4816\n",
      "Epoch 178/500\n",
      "112/112 [==============================] - 0s 153us/sample - loss: 0.3268 - val_loss: 0.4818\n",
      "Epoch 179/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.3263 - val_loss: 0.4822\n",
      "Epoch 180/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.3257 - val_loss: 0.4826\n",
      "Epoch 181/500\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.3251 - val_loss: 0.4831\n",
      "Epoch 182/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.3245 - val_loss: 0.4830\n",
      "Epoch 183/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.3240 - val_loss: 0.4827\n",
      "Epoch 184/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3236 - val_loss: 0.4825\n",
      "Epoch 185/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.3230 - val_loss: 0.4822\n",
      "Epoch 186/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3224 - val_loss: 0.4819\n",
      "Epoch 187/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.3219 - val_loss: 0.4821\n",
      "Epoch 188/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.3213 - val_loss: 0.4822\n",
      "Epoch 189/500\n",
      "112/112 [==============================] - 0s 155us/sample - loss: 0.3208 - val_loss: 0.4821\n",
      "Epoch 190/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.3204 - val_loss: 0.4816\n",
      "Epoch 191/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.3199 - val_loss: 0.4811\n",
      "Epoch 192/500\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.3193 - val_loss: 0.4805\n",
      "Epoch 193/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.3188 - val_loss: 0.4800\n",
      "Epoch 194/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.3182 - val_loss: 0.4794\n",
      "Epoch 195/500\n",
      "112/112 [==============================] - 0s 159us/sample - loss: 0.3177 - val_loss: 0.4792\n",
      "Epoch 196/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.3171 - val_loss: 0.4790\n",
      "Epoch 197/500\n",
      "112/112 [==============================] - 0s 168us/sample - loss: 0.3167 - val_loss: 0.4786\n",
      "Epoch 198/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3161 - val_loss: 0.4782\n",
      "Epoch 199/500\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.3158 - val_loss: 0.4778\n",
      "Epoch 200/500\n",
      "112/112 [==============================] - 0s 179us/sample - loss: 0.3151 - val_loss: 0.4776\n",
      "Epoch 201/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.3147 - val_loss: 0.4775\n",
      "Epoch 202/500\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.3140 - val_loss: 0.4773\n",
      "Epoch 203/500\n",
      "112/112 [==============================] - 0s 154us/sample - loss: 0.3136 - val_loss: 0.4773\n",
      "Epoch 204/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.3131 - val_loss: 0.4774\n",
      "Epoch 205/500\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.3127 - val_loss: 0.4773\n",
      "Epoch 206/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.3122 - val_loss: 0.4773\n",
      "Epoch 207/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.3117 - val_loss: 0.4771\n",
      "Epoch 208/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.3111 - val_loss: 0.4773\n",
      "Epoch 209/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.3108 - val_loss: 0.4773\n",
      "Epoch 210/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.3102 - val_loss: 0.4771\n",
      "Epoch 211/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.3098 - val_loss: 0.4770\n",
      "Epoch 212/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3093 - val_loss: 0.4771\n",
      "Epoch 213/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.3088 - val_loss: 0.4771\n",
      "Epoch 214/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.3084 - val_loss: 0.4770\n",
      "Epoch 215/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.3080 - val_loss: 0.4766\n",
      "Epoch 216/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.3075 - val_loss: 0.4763\n",
      "Epoch 217/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.3070 - val_loss: 0.4758\n",
      "Epoch 218/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.3065 - val_loss: 0.4754\n",
      "Epoch 219/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.3064 - val_loss: 0.4752\n",
      "Epoch 220/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.3060 - val_loss: 0.4752\n",
      "Epoch 221/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.3055 - val_loss: 0.4752\n",
      "Epoch 222/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.3051 - val_loss: 0.4749\n",
      "Epoch 223/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.3047 - val_loss: 0.4747\n",
      "Epoch 224/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.3042 - val_loss: 0.4746\n",
      "Epoch 225/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.3038 - val_loss: 0.4748\n",
      "Epoch 226/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.3034 - val_loss: 0.4753\n",
      "Epoch 227/500\n",
      "112/112 [==============================] - 0s 112us/sample - loss: 0.3029 - val_loss: 0.4758\n",
      "Epoch 228/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.3026 - val_loss: 0.4761\n",
      "Epoch 229/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.3022 - val_loss: 0.4761\n",
      "Epoch 230/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.3019 - val_loss: 0.4763\n",
      "Epoch 231/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 125us/sample - loss: 0.3014 - val_loss: 0.4762\n",
      "Epoch 232/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.3012 - val_loss: 0.4760\n",
      "Epoch 233/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.3009 - val_loss: 0.4753\n",
      "Epoch 234/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.3004 - val_loss: 0.4744\n",
      "Epoch 235/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2999 - val_loss: 0.4740\n",
      "Epoch 236/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2995 - val_loss: 0.4740\n",
      "Epoch 237/500\n",
      "112/112 [==============================] - 0s 146us/sample - loss: 0.2991 - val_loss: 0.4742\n",
      "Epoch 238/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2987 - val_loss: 0.4744\n",
      "Epoch 239/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2983 - val_loss: 0.4743\n",
      "Epoch 240/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2979 - val_loss: 0.4741\n",
      "Epoch 241/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.2975 - val_loss: 0.4737\n",
      "Epoch 242/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2972 - val_loss: 0.4735\n",
      "Epoch 243/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2968 - val_loss: 0.4734\n",
      "Epoch 244/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.2964 - val_loss: 0.4729\n",
      "Epoch 245/500\n",
      "112/112 [==============================] - 0s 151us/sample - loss: 0.2962 - val_loss: 0.4725\n",
      "Epoch 246/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2958 - val_loss: 0.4723\n",
      "Epoch 247/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2953 - val_loss: 0.4726\n",
      "Epoch 248/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.2950 - val_loss: 0.4731\n",
      "Epoch 249/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.2948 - val_loss: 0.4734\n",
      "Epoch 250/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.2945 - val_loss: 0.4733\n",
      "Epoch 251/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.2943 - val_loss: 0.4731\n",
      "Epoch 252/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.2939 - val_loss: 0.4729\n",
      "Epoch 253/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.2937 - val_loss: 0.4727\n",
      "Epoch 254/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2935 - val_loss: 0.4725\n",
      "Epoch 255/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2930 - val_loss: 0.4724\n",
      "Epoch 256/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2926 - val_loss: 0.4725\n",
      "Epoch 257/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.2921 - val_loss: 0.4726\n",
      "Epoch 258/500\n",
      "112/112 [==============================] - 0s 158us/sample - loss: 0.2920 - val_loss: 0.4730\n",
      "Epoch 259/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2916 - val_loss: 0.4733\n",
      "Epoch 260/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.2914 - val_loss: 0.4731\n",
      "Epoch 261/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.2911 - val_loss: 0.4725\n",
      "Epoch 262/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2908 - val_loss: 0.4722\n",
      "Epoch 263/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2905 - val_loss: 0.4724\n",
      "Epoch 264/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2903 - val_loss: 0.4729\n",
      "Epoch 265/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2900 - val_loss: 0.4729\n",
      "Epoch 266/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.2896 - val_loss: 0.4726\n",
      "Epoch 267/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2894 - val_loss: 0.4721\n",
      "Epoch 268/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2890 - val_loss: 0.4716\n",
      "Epoch 269/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.2888 - val_loss: 0.4712\n",
      "Epoch 270/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.2885 - val_loss: 0.4709\n",
      "Epoch 271/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2882 - val_loss: 0.4707\n",
      "Epoch 272/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.2878 - val_loss: 0.4710\n",
      "Epoch 273/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2876 - val_loss: 0.4717\n",
      "Epoch 274/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.2872 - val_loss: 0.4721\n",
      "Epoch 275/500\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.2870 - val_loss: 0.4721\n",
      "Epoch 276/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2867 - val_loss: 0.4721\n",
      "Epoch 277/500\n",
      "112/112 [==============================] - 0s 152us/sample - loss: 0.2866 - val_loss: 0.4721\n",
      "Epoch 278/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2864 - val_loss: 0.4722\n",
      "Epoch 279/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2862 - val_loss: 0.4724\n",
      "Epoch 280/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2859 - val_loss: 0.4725\n",
      "Epoch 281/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.2857 - val_loss: 0.4723\n",
      "Epoch 282/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2854 - val_loss: 0.4719\n",
      "Epoch 283/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2850 - val_loss: 0.4713\n",
      "Epoch 284/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.2847 - val_loss: 0.4709\n",
      "Epoch 285/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2846 - val_loss: 0.4708\n",
      "Epoch 286/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2844 - val_loss: 0.4712\n",
      "Epoch 287/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2842 - val_loss: 0.4715\n",
      "Epoch 288/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2839 - val_loss: 0.4720\n",
      "Epoch 289/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2838 - val_loss: 0.4723\n",
      "Epoch 290/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2835 - val_loss: 0.4721\n",
      "Epoch 291/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2834 - val_loss: 0.4717\n",
      "Epoch 292/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.2832 - val_loss: 0.4712\n",
      "Epoch 293/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2831 - val_loss: 0.4710\n",
      "Epoch 294/500\n",
      "112/112 [==============================] - 0s 102us/sample - loss: 0.2827 - val_loss: 0.4709\n",
      "Epoch 295/500\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.2822 - val_loss: 0.4712\n",
      "Epoch 296/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.2820 - val_loss: 0.4715\n",
      "Epoch 297/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2819 - val_loss: 0.4713\n",
      "Epoch 298/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.2817 - val_loss: 0.4710\n",
      "Epoch 299/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2816 - val_loss: 0.4709\n",
      "Epoch 300/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.2815 - val_loss: 0.4710\n",
      "Epoch 301/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.2812 - val_loss: 0.4714\n",
      "Epoch 302/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.2809 - val_loss: 0.4717\n",
      "Epoch 303/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2807 - val_loss: 0.4717\n",
      "Epoch 304/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.2804 - val_loss: 0.4716\n",
      "Epoch 305/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2803 - val_loss: 0.4715\n",
      "Epoch 306/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2800 - val_loss: 0.4716\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2799 - val_loss: 0.4716\n",
      "Epoch 308/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2800 - val_loss: 0.4715\n",
      "Epoch 309/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2796 - val_loss: 0.4711\n",
      "Epoch 310/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2794 - val_loss: 0.4710\n",
      "Epoch 311/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2793 - val_loss: 0.4708\n",
      "Epoch 312/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2789 - val_loss: 0.4704\n",
      "Epoch 313/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2788 - val_loss: 0.4702\n",
      "Epoch 314/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2784 - val_loss: 0.4704\n",
      "Epoch 315/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2783 - val_loss: 0.4707\n",
      "Epoch 316/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2783 - val_loss: 0.4708\n",
      "Epoch 317/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.2782 - val_loss: 0.4710\n",
      "Epoch 318/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2780 - val_loss: 0.4715\n",
      "Epoch 319/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2778 - val_loss: 0.4719\n",
      "Epoch 320/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2776 - val_loss: 0.4721\n",
      "Epoch 321/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2774 - val_loss: 0.4721\n",
      "Epoch 322/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.2771 - val_loss: 0.4722\n",
      "Epoch 323/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2769 - val_loss: 0.4724\n",
      "Epoch 324/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2768 - val_loss: 0.4729\n",
      "Epoch 325/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2767 - val_loss: 0.4727\n",
      "Epoch 326/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2766 - val_loss: 0.4722\n",
      "Epoch 327/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2767 - val_loss: 0.4720\n",
      "Epoch 328/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.2765 - val_loss: 0.4721\n",
      "Epoch 329/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2763 - val_loss: 0.4720\n",
      "Epoch 330/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2760 - val_loss: 0.4716\n",
      "Epoch 331/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.2757 - val_loss: 0.4715\n",
      "Epoch 332/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.2756 - val_loss: 0.4717\n",
      "Epoch 333/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2753 - val_loss: 0.4718\n",
      "Epoch 334/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2751 - val_loss: 0.4719\n",
      "Epoch 335/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.2749 - val_loss: 0.4717\n",
      "Epoch 336/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2749 - val_loss: 0.4717\n",
      "Epoch 337/500\n",
      "112/112 [==============================] - 0s 102us/sample - loss: 0.2749 - val_loss: 0.4717\n",
      "Epoch 338/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2747 - val_loss: 0.4715\n",
      "Epoch 339/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2745 - val_loss: 0.4714\n",
      "Epoch 340/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2743 - val_loss: 0.4712\n",
      "Epoch 341/500\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.272 - 0s 120us/sample - loss: 0.2741 - val_loss: 0.4707\n",
      "Epoch 342/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.2741 - val_loss: 0.4705\n",
      "Epoch 343/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2740 - val_loss: 0.4708\n",
      "Epoch 344/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2739 - val_loss: 0.4711\n",
      "Epoch 345/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2738 - val_loss: 0.4713\n",
      "Epoch 346/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2735 - val_loss: 0.4713\n",
      "Epoch 347/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2732 - val_loss: 0.4716\n",
      "Epoch 348/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2732 - val_loss: 0.4721\n",
      "Epoch 349/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2733 - val_loss: 0.4721\n",
      "Epoch 350/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.2733 - val_loss: 0.4719\n",
      "Epoch 351/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.2732 - val_loss: 0.4717\n",
      "Epoch 352/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2732 - val_loss: 0.4716\n",
      "Epoch 353/500\n",
      "112/112 [==============================] - 0s 104us/sample - loss: 0.2731 - val_loss: 0.4717\n",
      "Epoch 354/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2730 - val_loss: 0.4718\n",
      "Epoch 355/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2727 - val_loss: 0.4716\n",
      "Epoch 356/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2726 - val_loss: 0.4713\n",
      "Epoch 357/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2723 - val_loss: 0.4712\n",
      "Epoch 358/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2719 - val_loss: 0.4710\n",
      "Epoch 359/500\n",
      "112/112 [==============================] - 0s 148us/sample - loss: 0.2717 - val_loss: 0.4708\n",
      "Epoch 360/500\n",
      "112/112 [==============================] - 0s 114us/sample - loss: 0.2717 - val_loss: 0.4710\n",
      "Epoch 361/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2716 - val_loss: 0.4714\n",
      "Epoch 362/500\n",
      "112/112 [==============================] - 0s 161us/sample - loss: 0.2713 - val_loss: 0.4719\n",
      "Epoch 363/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2713 - val_loss: 0.4720\n",
      "Epoch 364/500\n",
      "112/112 [==============================] - 0s 162us/sample - loss: 0.2711 - val_loss: 0.4718\n",
      "Epoch 365/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2710 - val_loss: 0.4718\n",
      "Epoch 366/500\n",
      "112/112 [==============================] - 0s 156us/sample - loss: 0.2710 - val_loss: 0.4721\n",
      "Epoch 367/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.2709 - val_loss: 0.4724\n",
      "Epoch 368/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.2708 - val_loss: 0.4722\n",
      "Epoch 369/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2707 - val_loss: 0.4718\n",
      "Epoch 370/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.2705 - val_loss: 0.4714\n",
      "Epoch 371/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2703 - val_loss: 0.4712\n",
      "Epoch 372/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2700 - val_loss: 0.4715\n",
      "Epoch 373/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2700 - val_loss: 0.4718\n",
      "Epoch 374/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2700 - val_loss: 0.4720\n",
      "Epoch 375/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.2699 - val_loss: 0.4719\n",
      "Epoch 376/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2699 - val_loss: 0.4717\n",
      "Epoch 377/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.2697 - val_loss: 0.4717\n",
      "Epoch 378/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2697 - val_loss: 0.4721\n",
      "Epoch 379/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2696 - val_loss: 0.4724\n",
      "Epoch 380/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2694 - val_loss: 0.4722\n",
      "Epoch 381/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2694 - val_loss: 0.4719\n",
      "Epoch 382/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.2693 - val_loss: 0.4716\n",
      "Epoch 383/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2692 - val_loss: 0.4715\n",
      "Epoch 384/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.2690 - val_loss: 0.4716\n",
      "Epoch 385/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2690 - val_loss: 0.4716\n",
      "Epoch 386/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.2689 - val_loss: 0.4716\n",
      "Epoch 387/500\n",
      "112/112 [==============================] - 0s 150us/sample - loss: 0.2689 - val_loss: 0.4717\n",
      "Epoch 388/500\n",
      "112/112 [==============================] - 0s 115us/sample - loss: 0.2690 - val_loss: 0.4718\n",
      "Epoch 389/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2688 - val_loss: 0.4719\n",
      "Epoch 390/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2686 - val_loss: 0.4720\n",
      "Epoch 391/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.2685 - val_loss: 0.4723\n",
      "Epoch 392/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2683 - val_loss: 0.4725\n",
      "Epoch 393/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2683 - val_loss: 0.4727\n",
      "Epoch 394/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2682 - val_loss: 0.4728\n",
      "Epoch 395/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2683 - val_loss: 0.4729\n",
      "Epoch 396/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2683 - val_loss: 0.4730\n",
      "Epoch 397/500\n",
      "112/112 [==============================] - 0s 110us/sample - loss: 0.2682 - val_loss: 0.4731\n",
      "Epoch 398/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2681 - val_loss: 0.4731\n",
      "Epoch 399/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2679 - val_loss: 0.4729\n",
      "Epoch 400/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.2677 - val_loss: 0.4728\n",
      "Epoch 401/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2677 - val_loss: 0.4728\n",
      "Epoch 402/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.2677 - val_loss: 0.4731\n",
      "Epoch 403/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2675 - val_loss: 0.4730\n",
      "Epoch 404/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.2674 - val_loss: 0.4730\n",
      "Epoch 405/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.2675 - val_loss: 0.4732\n",
      "Epoch 406/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2674 - val_loss: 0.4734\n",
      "Epoch 407/500\n",
      "112/112 [==============================] - 0s 102us/sample - loss: 0.2674 - val_loss: 0.4738\n",
      "Epoch 408/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2673 - val_loss: 0.4740\n",
      "Epoch 409/500\n",
      "112/112 [==============================] - 0s 112us/sample - loss: 0.2672 - val_loss: 0.4739\n",
      "Epoch 410/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2671 - val_loss: 0.4739\n",
      "Epoch 411/500\n",
      "112/112 [==============================] - 0s 112us/sample - loss: 0.2670 - val_loss: 0.4737\n",
      "Epoch 412/500\n",
      "112/112 [==============================] - 0s 128us/sample - loss: 0.2668 - val_loss: 0.4734\n",
      "Epoch 413/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.2667 - val_loss: 0.4735\n",
      "Epoch 414/500\n",
      "112/112 [==============================] - 0s 105us/sample - loss: 0.2666 - val_loss: 0.4737\n",
      "Epoch 415/500\n",
      "112/112 [==============================] - 0s 164us/sample - loss: 0.2667 - val_loss: 0.4735\n",
      "Epoch 416/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2668 - val_loss: 0.4733\n",
      "Epoch 417/500\n",
      "112/112 [==============================] - 0s 111us/sample - loss: 0.2666 - val_loss: 0.4735\n",
      "Epoch 418/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.2666 - val_loss: 0.4738\n",
      "Epoch 419/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2663 - val_loss: 0.4741\n",
      "Epoch 420/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2663 - val_loss: 0.4742\n",
      "Epoch 421/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2661 - val_loss: 0.4743\n",
      "Epoch 422/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2661 - val_loss: 0.4744\n",
      "Epoch 423/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.2659 - val_loss: 0.4749\n",
      "Epoch 424/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2659 - val_loss: 0.4751\n",
      "Epoch 425/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.2657 - val_loss: 0.4748\n",
      "Epoch 426/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2656 - val_loss: 0.4745\n",
      "Epoch 427/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2656 - val_loss: 0.4745\n",
      "Epoch 428/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.2655 - val_loss: 0.4745\n",
      "Epoch 429/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2654 - val_loss: 0.4743\n",
      "Epoch 430/500\n",
      "112/112 [==============================] - 0s 145us/sample - loss: 0.2655 - val_loss: 0.4739\n",
      "Epoch 431/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.2653 - val_loss: 0.4735\n",
      "Epoch 432/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2652 - val_loss: 0.4734\n",
      "Epoch 433/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.2653 - val_loss: 0.4734\n",
      "Epoch 434/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2652 - val_loss: 0.4735\n",
      "Epoch 435/500\n",
      "112/112 [==============================] - 0s 135us/sample - loss: 0.2651 - val_loss: 0.4735\n",
      "Epoch 436/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.2650 - val_loss: 0.4740\n",
      "Epoch 437/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2649 - val_loss: 0.4745\n",
      "Epoch 438/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.2649 - val_loss: 0.4748\n",
      "Epoch 439/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2648 - val_loss: 0.4748\n",
      "Epoch 440/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2649 - val_loss: 0.4748\n",
      "Epoch 441/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2650 - val_loss: 0.4750\n",
      "Epoch 442/500\n",
      "112/112 [==============================] - 0s 140us/sample - loss: 0.2648 - val_loss: 0.4751\n",
      "Epoch 443/500\n",
      "112/112 [==============================] - 0s 101us/sample - loss: 0.2649 - val_loss: 0.4748\n",
      "Epoch 444/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2647 - val_loss: 0.4744\n",
      "Epoch 445/500\n",
      "112/112 [==============================] - 0s 107us/sample - loss: 0.2646 - val_loss: 0.4742\n",
      "Epoch 446/500\n",
      "112/112 [==============================] - 0s 147us/sample - loss: 0.2646 - val_loss: 0.4743\n",
      "Epoch 447/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.2646 - val_loss: 0.4743\n",
      "Epoch 448/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2646 - val_loss: 0.4743\n",
      "Epoch 449/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.2645 - val_loss: 0.4744\n",
      "Epoch 450/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.2643 - val_loss: 0.4746\n",
      "Epoch 451/500\n",
      "112/112 [==============================] - 0s 137us/sample - loss: 0.2642 - val_loss: 0.4745\n",
      "Epoch 452/500\n",
      "112/112 [==============================] - 0s 113us/sample - loss: 0.2642 - val_loss: 0.4745\n",
      "Epoch 453/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2641 - val_loss: 0.4746\n",
      "Epoch 454/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2640 - val_loss: 0.4747\n",
      "Epoch 455/500\n",
      "112/112 [==============================] - 0s 123us/sample - loss: 0.2639 - val_loss: 0.4745\n",
      "Epoch 456/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.2639 - val_loss: 0.4744\n",
      "Epoch 457/500\n",
      "112/112 [==============================] - 0s 106us/sample - loss: 0.2639 - val_loss: 0.4745\n",
      "Epoch 458/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.2638 - val_loss: 0.4746\n",
      "Epoch 459/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 124us/sample - loss: 0.2638 - val_loss: 0.4745\n",
      "Epoch 460/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2638 - val_loss: 0.4743\n",
      "Epoch 461/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.2638 - val_loss: 0.4743\n",
      "Epoch 462/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2637 - val_loss: 0.4744\n",
      "Epoch 463/500\n",
      "112/112 [==============================] - 0s 142us/sample - loss: 0.2636 - val_loss: 0.4747\n",
      "Epoch 464/500\n",
      "112/112 [==============================] - 0s 108us/sample - loss: 0.2636 - val_loss: 0.4746\n",
      "Epoch 465/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.2636 - val_loss: 0.4743\n",
      "Epoch 466/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2634 - val_loss: 0.4744\n",
      "Epoch 467/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2634 - val_loss: 0.4746\n",
      "Epoch 468/500\n",
      "112/112 [==============================] - 0s 136us/sample - loss: 0.2634 - val_loss: 0.4746\n",
      "Epoch 469/500\n",
      "112/112 [==============================] - 0s 141us/sample - loss: 0.2634 - val_loss: 0.4745\n",
      "Epoch 470/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2633 - val_loss: 0.4749\n",
      "Epoch 471/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2633 - val_loss: 0.4755\n",
      "Epoch 472/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2632 - val_loss: 0.4759\n",
      "Epoch 473/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2633 - val_loss: 0.4759\n",
      "Epoch 474/500\n",
      "112/112 [==============================] - 0s 122us/sample - loss: 0.2633 - val_loss: 0.4758\n",
      "Epoch 475/500\n",
      "112/112 [==============================] - 0s 138us/sample - loss: 0.2632 - val_loss: 0.4756\n",
      "Epoch 476/500\n",
      "112/112 [==============================] - 0s 125us/sample - loss: 0.2632 - val_loss: 0.4754\n",
      "Epoch 477/500\n",
      "112/112 [==============================] - 0s 139us/sample - loss: 0.2629 - val_loss: 0.4753\n",
      "Epoch 478/500\n",
      "112/112 [==============================] - 0s 109us/sample - loss: 0.2628 - val_loss: 0.4751\n",
      "Epoch 479/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2629 - val_loss: 0.4747\n",
      "Epoch 480/500\n",
      "112/112 [==============================] - 0s 131us/sample - loss: 0.2628 - val_loss: 0.4743\n",
      "Epoch 481/500\n",
      "112/112 [==============================] - 0s 143us/sample - loss: 0.2629 - val_loss: 0.4740\n",
      "Epoch 482/500\n",
      "112/112 [==============================] - 0s 116us/sample - loss: 0.2628 - val_loss: 0.4741\n",
      "Epoch 483/500\n",
      "112/112 [==============================] - 0s 129us/sample - loss: 0.2627 - val_loss: 0.4745\n",
      "Epoch 484/500\n",
      "112/112 [==============================] - 0s 133us/sample - loss: 0.2625 - val_loss: 0.4748\n",
      "Epoch 485/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2625 - val_loss: 0.4751\n",
      "Epoch 486/500\n",
      "112/112 [==============================] - 0s 121us/sample - loss: 0.2625 - val_loss: 0.4754\n",
      "Epoch 487/500\n",
      "112/112 [==============================] - 0s 126us/sample - loss: 0.2626 - val_loss: 0.4755\n",
      "Epoch 488/500\n",
      "112/112 [==============================] - 0s 132us/sample - loss: 0.2625 - val_loss: 0.4754\n",
      "Epoch 489/500\n",
      "112/112 [==============================] - 0s 117us/sample - loss: 0.2624 - val_loss: 0.4752\n",
      "Epoch 490/500\n",
      "112/112 [==============================] - 0s 127us/sample - loss: 0.2623 - val_loss: 0.4751\n",
      "Epoch 491/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2620 - val_loss: 0.4747\n",
      "Epoch 492/500\n",
      "112/112 [==============================] - 0s 119us/sample - loss: 0.2620 - val_loss: 0.4745\n",
      "Epoch 493/500\n",
      "112/112 [==============================] - 0s 130us/sample - loss: 0.2619 - val_loss: 0.4747\n",
      "Epoch 494/500\n",
      "112/112 [==============================] - 0s 120us/sample - loss: 0.2619 - val_loss: 0.4751\n",
      "Epoch 495/500\n",
      "112/112 [==============================] - 0s 124us/sample - loss: 0.2618 - val_loss: 0.4753\n",
      "Epoch 496/500\n",
      "112/112 [==============================] - 0s 144us/sample - loss: 0.2618 - val_loss: 0.4757\n",
      "Epoch 497/500\n",
      "112/112 [==============================] - 0s 118us/sample - loss: 0.2617 - val_loss: 0.4760\n",
      "Epoch 498/500\n",
      "112/112 [==============================] - 0s 149us/sample - loss: 0.2618 - val_loss: 0.4759\n",
      "Epoch 499/500\n",
      "112/112 [==============================] - 0s 134us/sample - loss: 0.2618 - val_loss: 0.4756\n",
      "Epoch 500/500\n",
      "112/112 [==============================] - 0s 102us/sample - loss: 0.2617 - val_loss: 0.4756\n"
     ]
    }
   ],
   "source": [
    "# model define\n",
    "# reduce to 40 features\n",
    "encoding_dim = 15\n",
    "\n",
    "# make input layer\n",
    "input_df = Input(shape=(156,))\n",
    "encoded = Dense(encoding_dim,activation='relu')(input_df)\n",
    "decoded = Dense(156)(encoded)\n",
    "\n",
    "# encoder\n",
    "autoencoder = Model(input_df, decoded)\n",
    "\n",
    "# intermediate result\n",
    "encoder = Model(input_df, encoded)\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "#train model\n",
    "history = autoencoder.fit(X_train, X_train,\n",
    "                epochs=500, # this was 250\n",
    "                batch_size=50, # this was 256\n",
    "                shuffle=True,\n",
    "                validation_data=(X_val, X_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a44f46250>]"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot learning curves to see whether there is a plateau\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'],color='red')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a45920190>]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# \n",
    "#encoded_X_train = encoder.predict(X_train)\n",
    "#encoded_X_val = encoder.predict(X_val)\n",
    "reconstructed_X_val = autoencoder.predict(X_val)\n",
    "#print(reconstructed_X_val[,0])\n",
    "#print(X_val[,0])\n",
    "i=7\n",
    "#plt.scatter(X_val[i,:],reconstructed_X_val[i,:]) # per brain measures\n",
    "plt.scatter(X_val[:,i],reconstructed_X_val[:,i]) # per individual\n",
    "plt.plot((-2.5,3),(-2.5,3),color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test this on the test data\n",
    "# Select brain data and scale from test data\n",
    "brainfeatures = X_srs_test.columns[15:197] # Separating out the features\n",
    "X_srs_brain_test = X_srs_test.loc[:, brainfeatures].values # Separating out the target\n",
    "X_srs_brain_test = StandardScaler().fit_transform(X_srs_brain_test)\n",
    "\n",
    "X_srs_brain_test_Df = pd.DataFrame(data = X_srs_brain_test)\n",
    "\n",
    "#print(X_srs_brain_test_Df)\n",
    "\n",
    "reconstructed_X_test = autoencoder.predict(X_srs_brain_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate MSE for each participants X_srs_brain_test and reconstructed_X_test\n",
    "rms = []\n",
    "for i in range(len(reconstructed_X_test)):\n",
    "    rms.append(np.sqrt(np.sum((reconstructed_X_test[i] - X_srs_brain_test[i])**2)))\n",
    "rms = np.array(rms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1a46952590>"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Regress MSE to SRS data\n",
    "X_srs_test_rms = X_srs_test.copy()\n",
    "X_srs_test_rms['rms'] = rms\n",
    "boys = np.where(X_srs_test_rms['GenderTwin'] == 'boys')\n",
    "girls = np.where(X_srs_test_rms['GenderTwin'] == 'girls')\n",
    "\n",
    "plt.scatter(X_srs_test_rms.iloc[boys]['C3.3_SRS_TotalScore_18'],X_srs_test_rms.iloc[boys]['rms'],color=\"blue\") #\n",
    "plt.scatter(X_srs_test_rms.iloc[girls]['C3.3_SRS_TotalScore_18'],X_srs_test_rms.iloc[girls]['rms'],color=\"red\") #\n",
    "#plt.scatter(X_srs_test_rms['C3.3_SRS_TotalScore_18'],X_srs_test_rms['rms']) #\n",
    "\n",
    "#plt.scatter(X_srs_test_rms['GenderTwin'],X_srs_test_rms['rms']) # \n",
    "#plt.scatter(X_srs_test_rms['AgeYears'],X_srs_test_rms['rms']) # \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split file in train and test dataset and stratify the split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AgeYears  GenderTwin\n",
      "0        89.0       False\n",
      "1        89.0       False\n",
      "2        87.0       False\n",
      "3        87.0       False\n",
      "4        92.0       False\n",
      "..        ...         ...\n",
      "584     111.0       False\n",
      "585     109.0       False\n",
      "586     109.0       False\n",
      "587     137.0       False\n",
      "588     137.0       False\n",
      "\n",
      "[589 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/pandas/core/ops/__init__.py:1115: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "# Convert boys/girls to true/false\n",
    "finalData['GenderTwin']=finalData['GenderTwin'] == 'boys'\n",
    "#print(finalData)\n",
    "finalData.shape\n",
    "X=finalData[finalData.columns[0:25]]\n",
    "X = pd.concat([X, finalData[['GenderTwin']]], axis = 1)\n",
    "\n",
    "#X=finalData[0:20]\n",
    "#print(X)\n",
    "#X=data[['GenderTwin','CortexVol','SubCortGrayVol','TotalGrayVol']]\n",
    "len(X)\n",
    "y=finalData[['AgeYears','GenderTwin']]\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42, stratify=X['GenderTwin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove gender from data frames\n",
    "\n",
    "y_train = y_train['AgeYears']\n",
    "y_test = y_test['AgeYears']\n",
    "#print(y_train)\n",
    "\n",
    "X_train=X_train[X_train.columns[0:25]]\n",
    "#print(X_train)\n",
    "X_test=X_test[X_test.columns[0:25]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Elastic net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt  \n",
    "import seaborn as seabornInstance \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = LinearRegression()  \n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Coefficient\n",
      "0      0.177970\n",
      "1     -0.560235\n",
      "2     -0.299501\n",
      "3      0.273003\n",
      "4      0.597691\n",
      "5      0.191963\n",
      "6     -2.589682\n",
      "7      0.434193\n",
      "8      0.192783\n",
      "9      1.146722\n",
      "10     1.018249\n",
      "11     1.444984\n",
      "12    -0.784464\n",
      "13     1.024284\n",
      "14    -0.526136\n",
      "15     0.019939\n",
      "16     0.961069\n",
      "17     0.288597\n",
      "18     0.869734\n",
      "19     2.101976\n",
      "20     0.001274\n",
      "21    -0.753715\n",
      "22     0.658887\n",
      "23    -0.776340\n",
      "24    -0.114117\n"
     ]
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(regressor.coef_, X_train.columns, columns=['Coefficient'])  \n",
    "#print(coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.plot(kind='bar',figsize=(50,50))\n",
    "#plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')\n",
    "#plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166.02505696135964"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred)  \n",
    "#print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "#print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "elastic=ElasticNet(normalize=True, max_iter=10000)\n",
    "search=GridSearchCV(estimator=elastic,param_grid={'alpha':np.logspace(-5,2,8),'l1_ratio':[.2,.4,.6,.8]},scoring='neg_mean_squared_error',n_jobs=1,refit=True,cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.001, 'l1_ratio': 0.2}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.fit(X_train, y_train)\n",
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-5,2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175.52821434090313"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs(search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.6,\n",
       "           max_iter=1000, normalize=True, positive=False, precompute=False,\n",
       "           random_state=None, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic=ElasticNet(normalize=True,alpha=0.1,l1_ratio=0.6)\n",
    "elastic.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Coefficient\n",
      "0      0.001660\n",
      "1     -0.015051\n",
      "2     -0.000000\n",
      "3      0.000000\n",
      "4      0.000000\n",
      "5      0.000000\n",
      "6     -0.109036\n",
      "7      0.000000\n",
      "8      0.000000\n",
      "9      0.016235\n",
      "10     0.004201\n",
      "11     0.025497\n",
      "12    -0.000000\n",
      "13     0.008210\n",
      "14    -0.000000\n",
      "15    -0.000000\n",
      "16     0.000000\n",
      "17     0.000000\n",
      "18     0.000000\n",
      "19     0.071463\n",
      "20     0.000000\n",
      "21    -0.000000\n",
      "22     0.000000\n",
      "23    -0.000000\n",
      "24     0.000000\n"
     ]
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame(elastic.coef_, X_train.columns, columns=['Coefficient'])  \n",
    "print(coeff_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103.38975831 103.42970669 103.50767855 103.36969657 103.41409453\n",
      " 103.65456709 103.76647965 103.29373764 103.43849008 103.14437749\n",
      " 103.21524468 103.30472924 103.5954361  103.14429243 103.01956283\n",
      " 103.0678917  103.02014269 103.41503836 103.6896378  103.34631557\n",
      " 103.44847474 103.44901357 103.38426067 103.60455855 103.30644587\n",
      " 103.50311025 103.13026685 103.66544585 103.00685623 102.97410744\n",
      " 103.56231671 103.36770158 103.2306157  103.43474134 103.7627895\n",
      " 103.09571267 103.14539946 103.25882762 103.40774591 103.42803399\n",
      " 103.29350699 103.63683426 103.5193625  103.25400522 103.33165171\n",
      " 103.67890241 103.40780073 103.44093054 103.56391859 103.49969417\n",
      " 103.51333895 103.27036058 103.279982   103.71953888 103.39691249\n",
      " 103.64103775 103.43345096 103.4304395  103.74177615 103.28034994\n",
      " 103.52458645 102.91199766 103.46356032 103.05754878 103.00334707\n",
      " 103.41468894 102.90808227 103.42374541 103.26253204 103.49933024\n",
      " 103.44451523 103.39644389 103.53053966 103.36323455 103.35941\n",
      " 103.52322455 103.12463054 103.27596622 103.4146109  103.13011812\n",
      " 103.02286338 103.30653491 103.4327572  103.22652157 103.30918389\n",
      " 103.48703866 103.2854945  103.11665099 103.57205448 103.14541551\n",
      " 103.57325313 103.32911523 103.7380868  103.45844285 103.52017234\n",
      " 103.14764299 103.23592377 103.17369368 103.38828682 103.72221073\n",
      " 103.56497538 103.25170326 103.00142465 103.37643404 103.47764083\n",
      " 103.70264963 103.44945335 103.23604551 103.48302498 103.33138615\n",
      " 103.08286533 103.57327964 103.48929122 103.3015623  103.30599016\n",
      " 103.34576682 103.49061988 103.17868591 103.48545141 103.18559747\n",
      " 103.48941047 103.15894426 103.26361619 102.99509442 103.52391218\n",
      " 103.65244639 103.62341372 102.90725436 103.25778426 104.02157884\n",
      " 103.55134655 103.59796847 103.19527768 102.96580895 103.11137644\n",
      " 103.42966214 103.22616688 103.28861048 103.23254268 103.45323078\n",
      " 103.36946434 103.31083218 103.4057112  103.08272883 103.54680151\n",
      " 103.44536095 103.68814947 103.29579711 103.85067525 103.50281764\n",
      " 103.53381252 103.38700829 103.43145141 103.654118   103.3746742\n",
      " 103.55289608 103.66162705 103.58045549 103.69470629 103.79868203\n",
      " 103.19641488 103.41538926 103.54063609 103.20651842 103.16773191\n",
      " 103.86067066 103.66311938 103.70494713 103.33847158 103.13218445\n",
      " 103.38743477 103.379403   103.36785485 103.38359012 103.93291614\n",
      " 103.41617924 103.40253863 103.46360289 103.6912115  103.48258514\n",
      " 103.28209053 103.45010357 103.54428611 104.02304178 103.42001862\n",
      " 103.42989774 103.24817091 103.54938991 103.59316083 103.71984563\n",
      " 103.23046966 103.2627995  103.71261624 103.57582028 103.37137714\n",
      " 103.13887667 103.28930555 102.8211673  103.42379324 103.57049048\n",
      " 103.13428288 103.88890734 103.66232758 103.24770588 103.72935918\n",
      " 103.59169517 103.63556275 103.45013603 103.38456763 103.55957906\n",
      " 103.49621553 103.43474796 103.81585484 103.46865563 103.72190581\n",
      " 103.73001674 103.59502433 103.17437915 103.76002793 102.82463275\n",
      " 102.9956659  103.60804606 103.53868885 103.59342576 103.55066717\n",
      " 103.15102855 103.59750225 103.47010135 103.65260161 103.42881291\n",
      " 103.41982526 103.36721869 103.2535245  103.42081902 103.45082786\n",
      " 103.6269193  103.13917237 103.47977878 103.45038824 103.47112066\n",
      " 103.24659304 103.48729797 103.40185702 103.06739519 102.95612522\n",
      " 103.28459054 103.22757525 103.54195871 103.7816656  103.15726935\n",
      " 103.16101506 103.71327285 103.00976113 103.30018013 103.28308045\n",
      " 103.28460109 103.35799203 103.44137316 103.13573656 103.49620777\n",
      " 103.40560213 103.4164237  103.18710166 103.40483063 103.32014724\n",
      " 103.20209031 103.47998147 103.49880577 103.36363673 103.57595503\n",
      " 103.4953445  103.45348011 103.33209417 103.78624556 103.38283147\n",
      " 103.35157825 103.58028716 103.34607116 103.43181334 103.65402561\n",
      " 103.486428   103.11120334 103.33099468 103.27074844 103.22580412\n",
      " 103.32306793 103.52982819 103.20530886 103.6507848  103.50615159\n",
      " 103.59528799 103.43048814 103.1148056  103.39347663 103.27780016\n",
      " 103.54569846 103.22102985 103.23866674 103.4325097  103.22793147\n",
      " 103.46073595 103.21974763 103.45656957 103.32882356 103.51244401\n",
      " 103.02478995 103.34445522 103.38739851 103.76523446 103.49285828\n",
      " 103.35011333 103.28002616 103.45998906 103.47674424 103.17801264\n",
      " 103.51425617 103.23709795 103.3935415  103.34333655 103.63554919\n",
      " 103.6352561  103.5323151  103.60332054 103.55015785 103.34923271\n",
      " 103.30828157 103.22680289 103.2231008  103.19357725 103.69627752\n",
      " 103.97332338 103.25439083 103.48884726 103.63470015 103.27237483\n",
      " 103.47940822 103.43279387 103.17317772 103.34575726 103.56294141\n",
      " 103.39356216 103.39901719 103.44490322 102.92286453 103.19428566\n",
      " 103.57036799 103.60734608 103.26545398 103.17034044 103.49135978\n",
      " 103.16065469 103.50053986 102.86027554 103.33938032 103.27678232\n",
      " 103.59064282 103.20614989 103.40690239 103.67360375 103.57913933\n",
      " 103.6048813  103.5128244  103.68133332 103.5062494  103.1800796\n",
      " 103.57544882 103.2788115  103.63317233 103.43434942 103.23937699\n",
      " 103.16577101 103.6028692  103.79784147 103.51501425 103.25752368\n",
      " 103.51940816 103.46049627 103.10144348 103.37087101 103.75087845\n",
      " 103.36745525 103.65762663 103.47945135 103.34380385 103.57799867\n",
      " 103.23204324 103.33501482 103.35339182 103.63025263 103.22186523\n",
      " 103.41938552 103.36858604 103.36267483 103.34910615]\n"
     ]
    }
   ],
   "source": [
    "#evalueer model op je training set, zie dat alleen intercept er is\n",
    "y_pred = elastic.predict(X_train) \n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2770b510>]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_train,y_pred)\n",
    "plt.plot((80,140),(80,140),color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From here I started with a random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(data['AgeYears'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "#data2= data.drop('AgeYears', axis = 1)\n",
    "\n",
    "##Ik heb labels als labels en X als dataframe, ik rename X naar features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>GenderTwin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.256594</td>\n",
       "      <td>7.144201</td>\n",
       "      <td>1.028775</td>\n",
       "      <td>0.208576</td>\n",
       "      <td>0.613567</td>\n",
       "      <td>-0.636847</td>\n",
       "      <td>3.018764</td>\n",
       "      <td>-0.944426</td>\n",
       "      <td>-1.810257</td>\n",
       "      <td>0.702187</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.291098</td>\n",
       "      <td>1.070177</td>\n",
       "      <td>-0.693139</td>\n",
       "      <td>-1.765233</td>\n",
       "      <td>-0.830774</td>\n",
       "      <td>-0.114889</td>\n",
       "      <td>1.213888</td>\n",
       "      <td>-0.490881</td>\n",
       "      <td>0.178354</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>-6.769122</td>\n",
       "      <td>2.826888</td>\n",
       "      <td>1.600380</td>\n",
       "      <td>-0.093221</td>\n",
       "      <td>1.745067</td>\n",
       "      <td>-1.161000</td>\n",
       "      <td>2.231682</td>\n",
       "      <td>0.853536</td>\n",
       "      <td>0.664507</td>\n",
       "      <td>0.619442</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.391207</td>\n",
       "      <td>-0.324175</td>\n",
       "      <td>-1.455109</td>\n",
       "      <td>-0.521784</td>\n",
       "      <td>1.275971</td>\n",
       "      <td>0.688323</td>\n",
       "      <td>1.643019</td>\n",
       "      <td>1.278546</td>\n",
       "      <td>0.494694</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-6.589661</td>\n",
       "      <td>-1.418561</td>\n",
       "      <td>2.305850</td>\n",
       "      <td>-1.284248</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.909764</td>\n",
       "      <td>0.869030</td>\n",
       "      <td>-0.548419</td>\n",
       "      <td>1.040086</td>\n",
       "      <td>-1.083769</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.168749</td>\n",
       "      <td>-0.254962</td>\n",
       "      <td>-1.273319</td>\n",
       "      <td>-0.188134</td>\n",
       "      <td>-1.560959</td>\n",
       "      <td>0.956928</td>\n",
       "      <td>-0.930453</td>\n",
       "      <td>-0.403490</td>\n",
       "      <td>-0.789706</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-5.641689</td>\n",
       "      <td>-0.801669</td>\n",
       "      <td>1.952305</td>\n",
       "      <td>-0.525579</td>\n",
       "      <td>-1.178766</td>\n",
       "      <td>0.210104</td>\n",
       "      <td>1.076218</td>\n",
       "      <td>-0.722336</td>\n",
       "      <td>1.836155</td>\n",
       "      <td>-0.868958</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.806319</td>\n",
       "      <td>-0.576657</td>\n",
       "      <td>-0.623178</td>\n",
       "      <td>-0.021198</td>\n",
       "      <td>0.590005</td>\n",
       "      <td>0.775686</td>\n",
       "      <td>-0.296009</td>\n",
       "      <td>0.363189</td>\n",
       "      <td>-0.892605</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.686448</td>\n",
       "      <td>-2.237390</td>\n",
       "      <td>-2.887076</td>\n",
       "      <td>2.397236</td>\n",
       "      <td>-0.756279</td>\n",
       "      <td>-5.875614</td>\n",
       "      <td>1.997932</td>\n",
       "      <td>3.435443</td>\n",
       "      <td>0.779190</td>\n",
       "      <td>-1.832852</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.183628</td>\n",
       "      <td>1.224308</td>\n",
       "      <td>-2.703452</td>\n",
       "      <td>-0.502632</td>\n",
       "      <td>0.168188</td>\n",
       "      <td>1.001514</td>\n",
       "      <td>-1.753117</td>\n",
       "      <td>0.863638</td>\n",
       "      <td>0.485058</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>584</td>\n",
       "      <td>13.471546</td>\n",
       "      <td>1.066882</td>\n",
       "      <td>2.395232</td>\n",
       "      <td>5.268390</td>\n",
       "      <td>-4.084004</td>\n",
       "      <td>-2.416234</td>\n",
       "      <td>-2.644794</td>\n",
       "      <td>-3.951302</td>\n",
       "      <td>0.239417</td>\n",
       "      <td>1.126321</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327234</td>\n",
       "      <td>-0.483049</td>\n",
       "      <td>1.725948</td>\n",
       "      <td>-1.672650</td>\n",
       "      <td>1.426650</td>\n",
       "      <td>-4.427054</td>\n",
       "      <td>3.039489</td>\n",
       "      <td>-0.262568</td>\n",
       "      <td>-1.532696</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>585</td>\n",
       "      <td>10.180158</td>\n",
       "      <td>-1.192308</td>\n",
       "      <td>3.638355</td>\n",
       "      <td>2.288925</td>\n",
       "      <td>1.838815</td>\n",
       "      <td>-2.779988</td>\n",
       "      <td>-0.282069</td>\n",
       "      <td>1.581031</td>\n",
       "      <td>-1.985017</td>\n",
       "      <td>-3.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981899</td>\n",
       "      <td>0.409662</td>\n",
       "      <td>0.430294</td>\n",
       "      <td>1.387044</td>\n",
       "      <td>0.790882</td>\n",
       "      <td>4.735767</td>\n",
       "      <td>0.124829</td>\n",
       "      <td>-1.133418</td>\n",
       "      <td>-2.188034</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>586</td>\n",
       "      <td>11.909950</td>\n",
       "      <td>-4.564609</td>\n",
       "      <td>1.781273</td>\n",
       "      <td>0.493676</td>\n",
       "      <td>0.148429</td>\n",
       "      <td>-4.443186</td>\n",
       "      <td>-0.363214</td>\n",
       "      <td>2.156111</td>\n",
       "      <td>-1.222666</td>\n",
       "      <td>-1.545118</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.434781</td>\n",
       "      <td>0.718020</td>\n",
       "      <td>-1.479188</td>\n",
       "      <td>1.755127</td>\n",
       "      <td>0.814415</td>\n",
       "      <td>2.325652</td>\n",
       "      <td>-1.255279</td>\n",
       "      <td>0.330316</td>\n",
       "      <td>-2.168210</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>587</td>\n",
       "      <td>3.167142</td>\n",
       "      <td>5.350452</td>\n",
       "      <td>-2.607876</td>\n",
       "      <td>-0.482061</td>\n",
       "      <td>0.099620</td>\n",
       "      <td>-0.340658</td>\n",
       "      <td>-2.181144</td>\n",
       "      <td>0.096971</td>\n",
       "      <td>-0.252467</td>\n",
       "      <td>0.194439</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.757788</td>\n",
       "      <td>0.325350</td>\n",
       "      <td>1.247998</td>\n",
       "      <td>0.733659</td>\n",
       "      <td>0.616078</td>\n",
       "      <td>-0.499003</td>\n",
       "      <td>0.410633</td>\n",
       "      <td>-0.941344</td>\n",
       "      <td>-0.030334</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>588</td>\n",
       "      <td>2.731686</td>\n",
       "      <td>5.003576</td>\n",
       "      <td>-2.418465</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.556902</td>\n",
       "      <td>-0.827902</td>\n",
       "      <td>-1.908692</td>\n",
       "      <td>0.434892</td>\n",
       "      <td>-0.192902</td>\n",
       "      <td>0.258904</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.492077</td>\n",
       "      <td>0.555682</td>\n",
       "      <td>0.673490</td>\n",
       "      <td>1.319414</td>\n",
       "      <td>0.043124</td>\n",
       "      <td>-0.411978</td>\n",
       "      <td>-0.638298</td>\n",
       "      <td>-1.213654</td>\n",
       "      <td>0.442803</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>589 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0     1.256594  7.144201  1.028775  0.208576  0.613567 -0.636847  3.018764   \n",
       "1    -6.769122  2.826888  1.600380 -0.093221  1.745067 -1.161000  2.231682   \n",
       "2    -6.589661 -1.418561  2.305850 -1.284248  0.010669  0.909764  0.869030   \n",
       "3    -5.641689 -0.801669  1.952305 -0.525579 -1.178766  0.210104  1.076218   \n",
       "4     9.686448 -2.237390 -2.887076  2.397236 -0.756279 -5.875614  1.997932   \n",
       "..         ...       ...       ...       ...       ...       ...       ...   \n",
       "584  13.471546  1.066882  2.395232  5.268390 -4.084004 -2.416234 -2.644794   \n",
       "585  10.180158 -1.192308  3.638355  2.288925  1.838815 -2.779988 -0.282069   \n",
       "586  11.909950 -4.564609  1.781273  0.493676  0.148429 -4.443186 -0.363214   \n",
       "587   3.167142  5.350452 -2.607876 -0.482061  0.099620 -0.340658 -2.181144   \n",
       "588   2.731686  5.003576 -2.418465  0.005819  0.556902 -0.827902 -1.908692   \n",
       "\n",
       "            7         8         9  ...        16        17        18  \\\n",
       "0   -0.944426 -1.810257  0.702187  ... -1.291098  1.070177 -0.693139   \n",
       "1    0.853536  0.664507  0.619442  ... -0.391207 -0.324175 -1.455109   \n",
       "2   -0.548419  1.040086 -1.083769  ... -0.168749 -0.254962 -1.273319   \n",
       "3   -0.722336  1.836155 -0.868958  ... -0.806319 -0.576657 -0.623178   \n",
       "4    3.435443  0.779190 -1.832852  ... -0.183628  1.224308 -2.703452   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "584 -3.951302  0.239417  1.126321  ...  0.327234 -0.483049  1.725948   \n",
       "585  1.581031 -1.985017 -3.026597  ...  0.981899  0.409662  0.430294   \n",
       "586  2.156111 -1.222666 -1.545118  ... -0.434781  0.718020 -1.479188   \n",
       "587  0.096971 -0.252467  0.194439  ... -1.757788  0.325350  1.247998   \n",
       "588  0.434892 -0.192902  0.258904  ... -1.492077  0.555682  0.673490   \n",
       "\n",
       "           19        20        21        22        23        24  GenderTwin  \n",
       "0   -1.765233 -0.830774 -0.114889  1.213888 -0.490881  0.178354        True  \n",
       "1   -0.521784  1.275971  0.688323  1.643019  1.278546  0.494694        True  \n",
       "2   -0.188134 -1.560959  0.956928 -0.930453 -0.403490 -0.789706        True  \n",
       "3   -0.021198  0.590005  0.775686 -0.296009  0.363189 -0.892605        True  \n",
       "4   -0.502632  0.168188  1.001514 -1.753117  0.863638  0.485058        True  \n",
       "..        ...       ...       ...       ...       ...       ...         ...  \n",
       "584 -1.672650  1.426650 -4.427054  3.039489 -0.262568 -1.532696       False  \n",
       "585  1.387044  0.790882  4.735767  0.124829 -1.133418 -2.188034       False  \n",
       "586  1.755127  0.814415  2.325652 -1.255279  0.330316 -2.168210       False  \n",
       "587  0.733659  0.616078 -0.499003  0.410633 -0.941344 -0.030334       False  \n",
       "588  1.319414  0.043124 -0.411978 -0.638298 -1.213654  0.442803       False  \n",
       "\n",
       "[589 rows x 26 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = X\n",
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "# Convert to numpy array\n",
    "features = np.array(features)\n",
    "\n",
    "# Using Skicit-learn to split data into training and testing sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2565939321833275, 7.144200609532169, 1.0287747712098818, ...,\n",
       "        -0.4908813668032425, 0.17835392078026616, True],\n",
       "       [-6.769122250860017, 2.826888327122429, 1.6003804704123406, ...,\n",
       "        1.278545903695918, 0.4946943586545841, True],\n",
       "       [-6.589661478207608, -1.4185613936247228, 2.305850428337603, ...,\n",
       "        -0.4034896677179943, -0.7897059103849238, True],\n",
       "       ...,\n",
       "       [11.909949592557274, -4.5646085250412325, 1.781273330432657, ...,\n",
       "        0.33031573193927855, -2.1682104041913317, False],\n",
       "       [3.1671416088075293, 5.350451738057413, -2.6078758547828995, ...,\n",
       "        -0.9413436224976102, -0.030334427206953427, False],\n",
       "       [2.731685903284489, 5.0035755451658375, -2.418465472941391, ...,\n",
       "        -1.213654299637033, 0.44280287073846536, False]], dtype=object)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                      n_jobs=None, oob_score=False, random_state=42, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 11.31 years\n"
     ]
    }
   ],
   "source": [
    "#Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'years')\n",
    "\n",
    "##Dus 1 jaar is ongeveer 1/8.66 * 100 -> gemiddelde fout in procenten als je het gemiddelde neemt (het naieve model)\n",
    "##Dat is beter dan dit model... (oeps / auch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06908421, 0.05188557, 0.02877403, 0.04506451, 0.02901732,\n",
       "       0.03868381, 0.13028161, 0.05517555, 0.03167031, 0.03734881,\n",
       "       0.04224326, 0.02877408, 0.03669556, 0.03218293, 0.02225422,\n",
       "       0.02223484, 0.03524535, 0.022184  , 0.0319962 , 0.05204138,\n",
       "       0.02131741, 0.04436245, 0.02638556, 0.0246581 , 0.03831936,\n",
       "       0.00211958])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 'GenderTwin']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.63 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.46508333 9.16491667 8.44008333 8.16783333 9.51441667 8.24591667\n",
      " 7.91516667 8.24308333 8.608      8.31325    8.81525    7.926\n",
      " 8.66316667 8.62216667 9.05225    7.90708333 9.00083333 8.81375\n",
      " 8.53725    8.38433333 7.99325    8.17716667 8.54825    9.05858333\n",
      " 9.1295     9.72966667 9.63233333 8.94266667 9.69725    7.96366667\n",
      " 8.9285     7.92475    8.39325    9.19175    8.83883333 8.23383333\n",
      " 9.55275    9.03225    8.42475    8.59508333 8.92575    8.21516667\n",
      " 9.44391667 8.52758333 9.07691667 8.72575    8.11       9.09608333\n",
      " 8.51116667 8.07583333 8.50508333 8.20316667 8.66666667 8.10083333\n",
      " 9.55233333 8.29491667 8.22391667 9.41608333 9.4755     8.31783333\n",
      " 8.67958333 9.08991667 8.48       7.93483333 8.4645     7.92725\n",
      " 9.23966667 8.034      8.43158333 8.31383333 8.4165     8.76275\n",
      " 8.67891667 9.00041667 9.31233333 8.81408333 8.29525    8.58483333\n",
      " 8.49691667 8.86466667 8.7065     8.63741667 8.23166667 9.03683333\n",
      " 7.93725    8.67575    8.95766667 7.78166667 8.83083333 8.92783333\n",
      " 8.94391667 8.64816667 8.71       8.39333333 8.7795     8.99508333\n",
      " 8.13425    8.1545     8.21883333 8.51083333 8.18725    8.08166667\n",
      " 8.54058333 8.94791667 8.33358333 9.11775    9.78433333 8.40058333\n",
      " 8.73933333 7.70608333 8.34533333 8.58758333 8.949      8.55658333\n",
      " 7.9375     7.9715     8.9615     8.80591667 8.43566667 9.34675\n",
      " 8.74325    8.3105     9.9115     8.91025    8.01708333 9.52166667\n",
      " 8.506      9.24883333 9.17608333 8.61691667 8.77375    8.15408333\n",
      " 9.22916667 8.30541667 8.29708333 8.48266667 8.73625    9.51166667\n",
      " 8.19508333 8.96241667 8.32158333 9.10983333 7.96       8.51991667\n",
      " 8.56841667 9.67641667 8.83116667 8.7305     8.51583333 8.96391667\n",
      " 8.48325    8.86066667 9.18166667 8.7465     8.66308333 8.60308333\n",
      " 8.86666667 9.09633333 8.468      9.452      8.54816667 8.949\n",
      " 8.42241667 9.00275    8.64841667 8.46991667 9.03116667 8.75791667\n",
      " 8.6445     8.561      7.95691667 8.38916667 8.90733333 9.89308333\n",
      " 7.941      8.08191667 8.37975    8.15825    9.24308333 8.751\n",
      " 9.44341667 8.58491667 8.80241667 9.12725    7.99658333 8.64866667\n",
      " 8.53241667 8.2295     9.57283333 8.50075    8.394      8.08225\n",
      " 8.57533333 8.46408333 9.18508333]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330    104.0\n",
      "28      99.0\n",
      "386     94.0\n",
      "385    108.0\n",
      "246     85.0\n",
      "       ...  \n",
      "79     106.0\n",
      "179     91.0\n",
      "240     85.0\n",
      "270     84.0\n",
      "487    125.0\n",
      "Name: AgeYears, Length: 394, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(195,)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.scatter(y_train,predictions)\n",
    "print(y_train)\n",
    "predictions.shape\n",
    "\n",
    "#plt.plot((80,140),(80,140),color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "scatter() missing 2 required positional arguments: 'x' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-169-a44159f130bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: scatter() missing 2 required positional arguments: 'x' and 'y'"
     ]
    }
   ],
   "source": [
    "scatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 589\n",
      "[1.0287747712098818 1.6003804704123406 2.305850428337603\n",
      " 1.9523045358767848 -2.88707597228685 0.25515226955320647\n",
      " -0.333762503906644 0.36550665660298554 2.059064623941877\n",
      " 2.5285379249026945 0.5611826700781628 -0.3645859932035965\n",
      " -3.5477532029916574 -2.3057284557560758 1.7823037075784536\n",
      " -1.5520162062478327 2.1166142805023775 5.3756119354110865\n",
      " -7.588057818858302 2.6303233756693025 1.791206023317836\n",
      " 1.2834624842892537 1.3079930950317418 0.44242580306987833\n",
      " -0.7169198080602842 -0.2817702901878623 0.004769824856469719\n",
      " 2.166185191962835 -0.06611788480876796 2.287196096981329\n",
      " 1.0255359244349986 0.706281355959978 0.16430468646557853\n",
      " -0.3081747501883081 -0.9903617992176054 -1.2448764262048553\n",
      " -1.885145281953883 0.4369079726537474 1.4662981633320469\n",
      " 0.18557124003739786 -0.031784619793844275 0.29138709868208257\n",
      " -1.0767441899140662 1.1040673689605578 -0.09188990365922359\n",
      " -1.6777608067576761 -1.0233476651233857 -0.8647792573729838\n",
      " -1.2135496027120554 -0.6822831957804208 -1.194968902640139\n",
      " 2.7570669941880994 2.9837185470376077 -1.1049771078194217\n",
      " 6.18015148871316 2.8715197202643763 -2.9612585632937978 3.406618788235225\n",
      " -0.08891605523831418 -0.7568796419166834 -0.7499867042442141\n",
      " -0.11294956645368548 -4.00345764610382 3.0021429970944866\n",
      " 3.2657478687936634 -1.4213550590247412 -3.123063476647038\n",
      " -1.0395438331062543 -0.34502467597880726 -1.1219874966264314\n",
      " 0.21875633653521734 -0.26212020238658784 -1.9006146775517152\n",
      " -1.7461645784568323 0.5206632867315029 0.41985088158767375\n",
      " 1.77375548195188 0.4643547685751353 1.1127439723647132\n",
      " 0.19062198797592517 1.5752778885395735 1.4509901567593293\n",
      " 1.0371432002483423 -0.11299018721704476 -1.3099391698886167\n",
      " -2.372532926236303 -0.41557813410360667 -1.927494084288338\n",
      " -1.6738344196064014 3.718133312513268 0.1041568903540628\n",
      " 2.013737693484207 3.037323412487917 -1.9510984166464536\n",
      " -2.9402001084028315 0.10592919188356704 -0.25453093944364547\n",
      " -1.6956973643805346 -3.3834708829599047 -0.05119266786637576\n",
      " -0.5529736662832538 -1.584567274469975 -3.365108102624443\n",
      " 0.08549965505078776 -1.3446891304039976 1.9105464060361887\n",
      " 2.7106642346174974 -1.729886738292125 0.011579038225437205\n",
      " -0.340437258384206 -1.9997064338164119 -1.1285040100430799\n",
      " -3.985046075518484 1.9127438315295446 0.9456997338712132\n",
      " -2.2808844391419076 -2.6626574656041364 -1.7918874396197557\n",
      " 1.2976587284303323 -0.6179370089070482 -1.1417258817209237\n",
      " -0.20995982110939174 4.185495394588662 2.2952318229869006\n",
      " 0.4731156892961555 2.154347516126501 -0.19059142427028955\n",
      " -1.9194275277684836 -2.705931177975911 1.1895574468781\n",
      " 0.05949358706170167 -1.0604435828925534 1.0653535623952222\n",
      " -1.3143025974817653 -0.9985372246510528 -3.2978321690116457\n",
      " -2.1058297746030403 -0.112944443485685 0.1897280655889992\n",
      " 0.8738237430725005 0.2739232737254312 1.2831695369968055\n",
      " -0.711481127888773 -0.11827238318202644 -0.5653117397272759\n",
      " -1.3162462536051038 -1.6921998372667713 -1.503983366419775\n",
      " 0.9105033289536215 0.7941266745775961 0.6586207982112121\n",
      " -0.016224159394072016 0.10579966979776144 -0.8840741601371633\n",
      " -1.2017174161350004 -2.429405083016798 -1.3385023509819822\n",
      " 0.4498114602921232 2.5211228038157065 3.4288582630961084\n",
      " -1.695361665762795 -1.009022834385521 2.1393169721482583\n",
      " 1.1765916668959429 -2.6337176929701562 -1.3984199396252408\n",
      " -0.43606771168040503 -0.3546515495750561 0.46021355730351626\n",
      " 2.166331275344188 -0.3905541247349727 1.0895471817558082\n",
      " 0.9067761163983004 -0.8110641194853251 -0.12506299665730147\n",
      " 0.3586774644202717 1.5216826365275713 -3.698022730029287\n",
      " 1.6552683999271383 0.9362622248444342 -0.857125143861211\n",
      " -0.4304940657986251 0.6105433654284048 -3.373749746228329\n",
      " -0.052110299584809644 0.6951627426843846 0.18385562066211875\n",
      " 0.00805609588608268 -2.6067522846606868 -1.640534472277712\n",
      " 0.5144952277715522 -1.3357064891299413 0.1484672689493965\n",
      " -1.5089436442428685 -1.5215434296976855 0.76041592657833\n",
      " -4.110454413890249 -1.8998203612444948 1.336003964999032\n",
      " 2.9103781319806727 1.7784042147473509 -0.28445577155292284\n",
      " 0.2398062971208515 -0.4015521633612643 -1.5563668003578661\n",
      " 0.3515271923100312 2.66395315405093 5.949622101776738 -3.627149964477999\n",
      " -1.0903927638341864 -3.2440484314363585 1.7768150468238562\n",
      " 0.9326534281152158 -0.45200767069766234 -0.9358928208821499\n",
      " 1.1643853582204609 -0.1844683275380355 -1.7194672556286497\n",
      " 0.30914566182192116 0.540116747817952 0.9895535319636583\n",
      " 0.06673093020430979 -0.07752555566069055 0.2972871220837365\n",
      " 0.21921572514813553 1.3155768842914826 -1.4429399148299542\n",
      " 0.7718135312184496 -0.061021024945415316 -1.0867054139899799\n",
      " 1.0423480545962602 1.598205813842726 0.3979673652609506\n",
      " 0.7399941375929627 1.0125338969241189 1.3398379844791883\n",
      " 6.408642304247482 -0.3071870195519422 2.208201146017461\n",
      " 2.1864597627258155 -7.023816907336594 7.978293753892884 5.718709095876495\n",
      " -1.7647355363245003 -0.5504014474855201 -0.015646882721653203\n",
      " -0.12058946556055399 0.21670102543402198 0.5328177737207762\n",
      " -3.263247742464244 0.1263937818459664 -1.6541739753797817\n",
      " -2.563587055133868 0.8998598717399846 1.595625411917013\n",
      " 1.6104947769102194 -1.8671087542726323 -0.3217761618182456\n",
      " 1.3928572665240775 0.051168009268775856 -1.1834252146824815\n",
      " -0.17091323626341146 1.1071056289575874 1.8067926276953072\n",
      " 1.489089414152551 1.2112393929381728 -0.9487853736499705\n",
      " 1.0740582152833527 0.21170606320178734 2.2570216211796574\n",
      " -0.2580466761284208 2.094797316654063 1.4780888290267202\n",
      " 1.3613637153137008 -0.48325812001886864 -1.869332057527069\n",
      " 2.033093080666736 1.4879046912987521 -1.8627098481779727\n",
      " -1.4943639748126747 -2.934746014205541 -0.41293748022885585\n",
      " 2.184386217851923 1.7838921746395489 -1.2316166317287196\n",
      " -2.8700990199684226 -0.37758062088632244 3.729458636065184\n",
      " -2.9127511032672087 -1.558881739918373 1.0529049567869795\n",
      " 1.301622196136547 0.9263143806706922 0.02500677456813002\n",
      " -0.19853981324290873 -0.7746161479424972 -0.006748023706489199\n",
      " 0.6344090825931228 0.455061697935842 -0.3933424390013457\n",
      " 0.25999856520877096 0.6537224322608833 2.7046083782371597\n",
      " 1.741138488020714 0.632147415625813 0.26326146086986363\n",
      " 0.7018299031182587 -0.7523266287364553 0.9614783773982263\n",
      " 0.15723775415663252 -1.0839187089265538 -1.2264204798027663\n",
      " -0.5879688296072741 -0.9421928996010133 -1.5145038706738694\n",
      " -0.31653364953947316 -0.8862777768490249 -0.06621029192446067\n",
      " -1.024881046137641 1.5280667582895575 -5.957238462615152\n",
      " 1.1837362362832426 1.3261294700888742 1.783036355294368\n",
      " -0.061830568163550585 0.11439425030020313 -1.2258300960967587\n",
      " 0.43809364794141137 -1.307344545840711 -3.0165937396066465\n",
      " 0.2743690684307875 0.05512224877404188 0.7040320736797945\n",
      " -0.6262464697838467 0.17072006169939485 -1.6003662004216856\n",
      " -0.28304195100543245 1.5860604536497898 -0.3722291222034151\n",
      " -3.2799067242872746 -2.8076717236128643 -0.015288117471243546\n",
      " 0.43673101318835844 0.3904471818723035 0.7708591722515507\n",
      " -0.6547517905766361 1.0242356515397864 -0.40531412544409895\n",
      " 1.1902849443766939 -0.6066856740767143 4.428114991931304\n",
      " 4.152134765957846 1.13305831372577 0.3530162747790478 1.847168187262234\n",
      " -0.3801435402898662 -0.5807336290462871 -0.25101512168138174\n",
      " -1.5105703407656619 -2.4482329246764745 -1.7214840757455339\n",
      " 1.2809291413448334 -0.2905526328816437 0.29935641312358924\n",
      " 0.7731609061016224 1.6726441584940976 3.361204073919096\n",
      " -2.2012919530085617 -1.5435722771829274 0.08727196099554319\n",
      " 0.3613279884700646 1.412202485989784 0.7162004562382465\n",
      " -1.1521491182203443 1.606932349286292 2.5256702024699207\n",
      " -1.5312086940817158 0.371325918687256 -1.498848019819389\n",
      " 0.32559576366917786 0.7129297844166069 -2.0102589223293164\n",
      " -1.9270933105996335 -2.008952810846991 -0.13391952189529874\n",
      " 0.08134246509301807 2.48115784848637 1.1756618049519583\n",
      " -1.2010864186591093 3.129731657016597 3.1442768921257565\n",
      " 0.003206609217334457 2.1910411884929624 0.33185402059655095\n",
      " 6.03077468142164 -1.953666163558703 -1.182892903648027\n",
      " 0.40603991367337006 -0.5655655442521917 -3.925317052200983\n",
      " -1.808997662018118 2.53256212953008 0.07934395077304805\n",
      " -0.6855998423996259 3.185866414185364 5.999542463108536\n",
      " -6.758500747301582 1.852573881034408 5.151938483959198\n",
      " -1.5337367172286416 2.5636253113702825 -3.3227288588609953\n",
      " 3.3957451626625907 0.5372884251843433 -5.007713494567229\n",
      " 2.7986331244262357 3.7265933752524223 -1.6923282155674793\n",
      " -0.6374386780435359 -1.4006998461767 -0.863804364366992\n",
      " -0.7869052235798256 -0.04476627510464385 0.017900827263388954\n",
      " -0.4723871588894698 0.050538367664485634 0.0972548078992807\n",
      " -0.5348765603158494 -1.0863380099730242 -0.6182931088368486\n",
      " -0.43889795305054913 -2.589051602041118 0.20593996514953702\n",
      " 0.5529172590123528 -1.4627954930350549 1.8939764702503405\n",
      " -0.05283690106854722 -0.5371574068124437 -1.2133206923030648\n",
      " -2.7608065600022558 -0.7997240491288662 -3.5295555146090205\n",
      " -2.318972853413311 -2.325286809763371 -1.6878961671949257\n",
      " -1.8906856573225168 1.971501676030482 -3.0229923530527896\n",
      " 1.5720144464440367 0.8893248971525884 -2.727884783066942\n",
      " -1.907647666127987 -1.5990424484433265 0.6882200748190741\n",
      " -1.195907828771951 -0.2145517282050311 -0.6983697637999285\n",
      " 3.9323451256974655 1.4527999153985451 -1.4639976543246527\n",
      " -0.8892948512905197 0.40009689853679203 0.9033975903229704\n",
      " -0.08053372196917354 1.3836407475584849 -1.0414670055399413\n",
      " -1.2395869534165338 0.6960505441840973 -0.8558772294235576\n",
      " -1.7873987554043398 -0.5223369748507062 1.375769859676134\n",
      " 0.7700792999005808 1.153447063953154 0.8024626879942275\n",
      " -0.24052116247281077 2.0105137123449937 2.236738368424532\n",
      " 1.2933229804726791 -1.5013750487600765 2.2108218009729077\n",
      " 0.7404303035031318 -0.3875228255296729 -2.598337344604982\n",
      " -1.2323539459431914 -0.4217228648341738 -1.7001022982879253\n",
      " -0.7514834453779564 1.3303606929109317 -3.2231928027719983\n",
      " -1.477662202603074 2.1771135877638756 2.8090564663144444\n",
      " -1.2554197941875496 -0.1945636172026316 -0.8556444814732459\n",
      " 3.5227535298952297 6.500527371719245 -2.763665688554233\n",
      " 0.9850246083422634 -5.06968370412744 3.4337968636720304\n",
      " -0.9158274369910154 3.0880813513442726 2.822525598710037\n",
      " -7.2245077159579525 0.2761021799450126 9.273732643298253\n",
      " 7.1415285341708135 5.008446096439043 1.096829524446788\n",
      " -0.017855211642296382 1.5657213067117643 -0.03748416452660207\n",
      " -3.228362682517937 0.9916254609963988 0.9187375249120793\n",
      " 0.7749161113604094 1.3750838079359744 -0.11069740975092904\n",
      " 1.7506285314457857 -0.9095971653931579 0.1372637619314065\n",
      " -0.631741966722444 2.3265310276826034 1.3225157370347216\n",
      " 1.3823357318740583 -1.4893185905321271 -1.9257586569024439\n",
      " -2.6597994005378833 -2.698023676631006 -2.8891315367218824\n",
      " -0.009736162078800414 -0.40135869275093683 -1.4664237040105221\n",
      " -2.3675677259185752 -0.764365838215154 3.2901177626269678\n",
      " -3.33584277010272 -1.6350828568181666 0.6703103446726657\n",
      " -1.1116346859809203 -0.7314529365694937 0.3639198271784873\n",
      " -1.1213505194201276 -1.7848955111965197 -0.9133948291148685\n",
      " -0.023961828648464342 -1.228456028084276 -0.5097070366148347\n",
      " -1.6627047350611102 -0.03345377973550282 1.242537567457665\n",
      " -5.110839976540915 1.4761150895891 0.5170208364606608 0.1651075186700069\n",
      " -1.404285594969476 -2.8271389174043704 0.5044508781004989\n",
      " 0.5027663261222325 -0.7748643023317376 -0.9657664147002869\n",
      " -1.3035737304001134 -3.2246581204067626 -3.3352736184675957\n",
      " -0.22127386926941472 -0.28737348963831816 -1.5464753491196948\n",
      " -0.8059306110697452 -0.24548277458048248 -0.726818639856388\n",
      " 2.273277167587428 1.3240986216481438 1.2767328094373758 3.711642325295467\n",
      " -1.0687364782082893 -0.5898039612431286 1.5902228394218267\n",
      " -0.24315532183658972 -0.09189701129002224 0.40002803871892\n",
      " -0.7418255932457664 0.5911647145390911 2.395231846363626\n",
      " 3.6383552266176236 1.781273330432657 -2.6078758547828995\n",
      " -2.418465472941391]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO2df5Ad1XXnv2dmntCMSHjCjG0YJCRTRLJBlmVPkLKqTSGcIIwxzNoQowob4riWcgr/gCKTSEE2sCuXtTtbi73rjavYmLVd8spCMhlDZK/stVShiirhHRiNZQWRxQYkPWQzjjRyYAZ4mjn7x3v91K/n3u7bv2/3O58qlWb6dd8+fbvfne5vf+85xMwQBEEQykVX3gEIgiAIySODuyAIQgmRwV0QBKGEyOAuCIJQQmRwFwRBKCE9eQcAABdddBEvW7Ys7zAEQRAKxTPPPPNrZu5XfWbF4L5s2TKMjY3lHYYgCEKhIKKXdZ+JLCMIglBCZHAXBEEoITK4C4IglBAZ3AVBEEqIDO6CIAglJNAtQ0SPALgRwKvMfJXns78AMAKgn5l/TUQE4CsAbgAwDeBPmfnZ5MMWhHZGx2sY2fc8XpmawSXVXgxvXIGhNQOR1xOEomNy5/4NANd7FxLREgB/COCYa/GHAFzR/HcngK/FD1EQ/Bkdr2HLY4dRm5oBA6hNzWDLY4cxOl6LtJ4glIHAwZ2ZnwRwSvHRQwD+EoA7Z/DNAL7FDQ4CqBLRxYlEKggaRvY9j5n6bNuymfosRvY9H2k9QSgDkTR3IroJQI2ZJzwfDQA47vr9RHOZqo07iWiMiMYmJyejhCEIAIBXpmaMlpuuJwhlIPTgTkR9AO4D8AXVx4plymogzPwwMw8y82B/v3L2rCAYcUm112i56XqCUAai3LlfDmA5gAkiegnApQCeJaJ3onGnvsS17qUAXokbpCD4MbxxBXor3W3LeivdGN64ItJ6glAGQueWYebDAN7u/N4c4AebbpnHAXyaiL4DYC2AM8x8MqlgBUGF43YJcsGYricIZYCCaqgS0U4A1wC4CMCvANzPzF93ff4Szg3uBOCraLhrpgF8gpkDM4INDg6yJA4TBEEIBxE9w8yDqs8C79yZeVPA58tcPzOAu8IGKAiCICSLzFAVBEEoITK4C4IglBArinUIQhCSXkAQwiGDu2A9TtoAZ3apkzYAQNvAbbqeIHQCIssI1iPpBQQhPDK4C9Yj6QUEITwyuAvWI+kFBCE8MrgL1iPpBQQhPPJCVbAeSS8gCOEJTD+QBZJ+QBAEITx+6QdElhEEQSghMrgLgiCUENHcBcEA3cxXmREr2IoM7oIQgG7m69jLp/DdZ2oyI1awEpFlBCEA3czXnU8flxmxgrXI4C4IAehmuM5qnGYyI1awAZFlUiJPLVZ04GS5pNqLmmLA7iZSDvAyI1awAblzTwFHo61NzYBxTosdHa+Vet9lRTfzddPaJTIjVrAWGdxTIM/shJIZMXmG1gzgSx9dhYFqLwjAQLUXX/roKmwbWqVcLk9Jgg2ILJMCeWYnlMyI6TC0ZkA5aOuWC0LeyOCeAjqNNgstNs99m2LbO4E8qzwl2aZt/Srki8gyKZBndkLbMyPa9k7ANJ404k6yTdv6VcgfGdxTQKfRZnEXlee+TbDtnUCeVZ6SbNO2fhXyR2SZlIiqxSbxaG267zwe43Xaf21qBpdv+T5mmdFNhE1rl2Db0Crjdr3HsmFlPw4cnURtaqZlWaz2VkAETE3XW8cbt8pTbWoG7/78D/BGfS50Hyb5fkTetQhe5M7dIrJ8tM7rMd5P+3c847PM2HHwGLaOHjZqU3UsOw4ea717cNqdmqnj9HS97Xh7K+qvQLWvYhz3TH0uUh8mWTlKqlAJXmRwt4gsH63zeoxXvRPQsfPp40brqY7FhJn6LGbOzik/885NMo07TB8m+X7E9nctQvYEDu5E9AgRvUpEP3Mt+w9E9FMiOkREPySiS5rLiYj+KxG90Pz8/WkGXzayfLTO6zFe9U5Ah256v5c4Met2cWam3va7E3eS8ST5fsT2dy1C9pho7t8A8FUA33ItG2HmzwMAEX0WwBcAfArAhwBc0fy3FsDXmv8LBmRpY4y7L7fGfYFCy/YbVNzvBEbHa7h71yHlet1Eyv1596E7FhO6CJhTDPBOP3j3q1tfta0JSfrkxXMvuAm8c2fmJwGc8iz7jevXRQCcy/1mAN/iBgcBVIno4qSCLTtZPlrH2ZdX41Zp2Sa6s9OOjk1rlyj3593HhpX9gftSUemmc1euZ/nwxhXK/arWdyNSiGALkTV3IvoiER0H8Mdo3LkDwAAAt1B6orlMMCDLR+s4+wrSuE11Z792bl+3tOWWCXo/cODopLIN587f+b/aW8HivkrreBct6IFKcV+0oAdDawaU+50D0FvparXZRY3fRQoRbCOyFZKZ7wNwHxFtAfBpAPcDINWqqu2J6E4AdwLA0qVLo4ZROrJ8tA67L0eiMJFATHRn3ToEtNkgg94P+KXkJQDvvGDhPKnITw5y9HZdu2/U5/Di9g8rPxsdr2H99v0yS1TInSTcMv8LwMeaP58AsMT12aUAXlFtxMwPM/MgMw/290d7rBaywy1RmGCiO5va94LW89uXSsYJkoOC2tUtl1migk1EGtyJ6ArXrzcBONr8+XEAf9J0zawDcIaZT8aMUbCAMHZDU93ZVPcPWs/EpuiWcfyOJahdv2OTWaKCTQTKMkS0E8A1AC4iohNoyC83ENEKNCTIl9FwygDA9wHcAOAFANMAPpFCzEIOhLEbmurOzjpBs2SD1vN+rnvnGSTjeGM3jc/bvulyQUiTwMGdmTcpFn9dsy4DuCtuUEI7NmT7M7UbDlR7Q8VmqvsHref+fP32/b42T92xqGIP816iCBk5hc5BZqhaji06ron0YYsNMIqMk0TsMktUsAkZ3C3HFh1XZZ28fd1SK2dEBtk807KcyixRwSaIDad4p8ng4CCPjY2F3s4GuSJtlm/eq9WQv/zx95XueB22jh7GzqePh84S2QnXhO3IOcgOInqGmQdVnxU25a8jVzh3tY5cAaBUF5Kf1l3G4wUaA/uOg8davztZIgH4DvCdck3YjJwDeyisLGOLXJE2flp3GY8X0GeDDMoS2SnXhM3IObCHwt65d4rtzLnb0c2mLNvxAvpskEFZIjvlmrAZOQf2UNjBvZNsZ06ek7Icb5Am61RO8uLOEqlCd01U+yqxUgIExZtngW3b6KTvpe0UVpbpNNtZWY7XxNrpZIP0olvuoOqjSjfhtTfORraSBsWbZ4FtGynLdVoGCju4d5rtrCzHa6LJbhtahdvXLW3L6ujOEqlD1UeLFvSg7knAHkYDDoo3zwLbNlKW67QMFFaWATqvOIH3eIuYgdBUk902tCpUgWwHbx8t37xXuZ5pAjS/eEfHa9p2TAtsm2jRRZNzOu17aSuFvXPvdIr6mJ91IWdduwQY9ZVu+2pfxSizpMMFvRXlerrlDkU9z0L+yOBeUIr6mJ+1Jju8cYW2yIBJX+niZYZRZkkH3bvggHfEhT3PQv7I4F5Qimo5y1qTHVozEJglMmh7VbzeAtpuVMczNa1eX7c8KEbbz7OQP4XW3DuZpC1nYXTdqBqwd7uHYqZPME1RMBCzr1Qass6aqsuKGfV86bbrIsLoeE20bUGL3LkXlCTljTC6blQNOGnt2ElR4PjhnRQFW0fn6+BpSEFh24wag26G8iyzaO+CLzK4F5Qk5Y0wum5UDThp7ThMioI0pKCwbUaNwdlONYFLtHfBj1LJMkWzjMUlKctZGF03qgacpHY8Ol4LnaLApK/CXj9h+99Zf3S8hgefOIK7dx3C3bsOodpbwQM3Xek761V3XHlo73l/z/Lef1EozeAu2eiiE0YPTlo7DvuOIKi4dVCKgqB2075+RsdrGN4zgfrsucF6aqaO4d0TrX2pYiFA+WI462n9eX/P8t5/kSiNLCOWseiE0YOT1I6j6N5BhbqDUhSEaTeN62dk3/NtA7tDfY59Z70yMM/Smce0/ry/Z3nvv0iU5s5dLGPRCVMIOmzR6LjbefE7nyYpCsK2m/T149deUAFvRkOrz1OOyPt7lvf+i0RpBndbstEVVQ8Mox9H1frDpE/Q9aNfceuoAzvgbzlcvnkvLqn2YsPKfuz96UmcbnrTVVp51P04nwGNWatTCh/9QLUXT22+1nhfaZD39yzv/ReJ0sgyNmSjk6ni5vj1ld9nWRa3BhovaJ0Ydhw81hrYgXNaeZjzO7xxBSrd898LVLoIwxtXYHS8htffOqv9PG/y/p7lvf8iUZo796Qe++PgpwcW4e49S4K0U91nzp1r0ufZe/10aXLKe3G08jBPPQDw4BNHlE8A67fvV2ry5y/sseIayvt7lvf+i0RpBncg/2x0ogeaE6WvnM+inucgyczdri6bpIpaM0OkNya//fUt6MHUdL21HADWb9+vlWyC0hRkSd7fs7z3XxRKNbjnjeiB5gT1VdL9GNZC56eNq3BbGf32N/byKXz3mVrb8uE9EwBjXt55bzyCEIbSaO42IHqgOX59lUY/hrXQ+RUmV+G2Mvrtb+fTx+ctr8+y78Au15AQBblzTxDRA80x6ask+zGsDKSKb8PKfuw4eMxoH7p2TXR8NwNyDQkRCRzciegRADcCeJWZr2ouGwHwEQBvAfg5gE8w81Tzsy0APglgFsBnmXlfSrHnQhjd1mZssGzq+iqN2KJIZqr4DhydDLQy+u1PN9NUhQ3WRwcbrhchHCayzDcAXO9Z9iMAVzHzewH8E4AtAEBE7wFwG4Arm9v8DRGZP9taTlmsjjYfR1qxJSX1BFkZ29brmr9eVxfNW17pnr/MJinG5utF0BM4uDPzkwBOeZb9kJkdM+5BAJc2f74ZwHeY+U1mfhHACwCuTjDeXCnL1GebjyOt2JLKDDm0ZgAjt6zG4r5z5fGqvRWM3Lp63hPc+QvnPxjPzjHOX9jTFsfILasxcutqa4tK23y9CHqS0Nz/DMCu5s8DaAz2Dieay+ZBRHcCuBMAli5dmkAY6VNEq6Pqcdrm40gztqRkIHd2R2c7Z6Bzb+dXfWn8C9cp27URm68XQU8stwwR3QfgLIBvO4sUqyklRmZ+mJkHmXmwv78/ThiZkXVx57joHqd1RZltOI6s+zjN4iNFu150lOU4Oo3IgzsR3YHGi9Y/Zm5ZAE4AcKfluxTAK9HDs4uiWR11j9NEsPY4su7jNIuPFO160VGW4+g0Ig3uRHQ9gL8CcBMzT7s+ehzAbUR0HhEtB3AFgJ/ED9MOsi7uHBfdY/PUdN3a48i6j9MsPlK060VHWY6j0yAO8N0S0U4A1wC4CMCvANyPhjvmPAD/3FztIDN/qrn+fWjo8GcB3M3MPwgKYnBwkMfGxiIegt3kaSHTTWePY7FLojh2ta8CZuDMTN23Dfc2F/RWQNT4w6TbPkpsUfvIb7vhjSvwwONHWpkdF/dVcP9HwmWPLAtioUwXInqGmQeVnwUN7llQ1sHdOwUdaDzOZnXXk/T+o7an2s6Nqo2gbbzbf+wDA23T+k1jcwptewnKDa/ri499YAC7fnJ83ozTSjdh5JbVHTWw5X39dwJ+g7ukH0iRvC1kST9OJ6lPB7URtI13e9W0fpPYDhydDLXcQde3B45OKlMJ1Ge546yDeV//nY6kH0gRGyxkSRaGTlqfduPNrBi2j6IUkB4dr2lnmwZt5+6vhz7+vlbc9+w6pN0uy/Nugxxiw/Xfycide4oUwUIWxgoY9XhMj9e937B9pCuMrWvHKVStw287v/7yizur827LjNIiXP9lRgb3FCmChSzMo3OSxbFVuPcbJitjb6Ubm9YuCRWbrlA10Jis4bedX3/p0g5UurOrpGSLHFKE67/MiCyTIkXIEhnm0Tmp4tjVvkpbuTrVfr3bmLhlBi+70Dg2P2mAoZ8tGtRfznZ5umVskUOKcP2XGRncUybNLJFJ6KphsyUmVRxbZyU0eWTvW9CDDSv7ceDoZNvUfzevv3kWDz5xBHfvOoTuZsk8d/rcoGIc67fvV/anSX+lVSnKdBubisYUJUtqGRFZpqAkpavm9egctF/v8U3N1HF6ut5WrNp97MN7JjC8e2Le+sC5l63eQtuq7I4Ouv5Mq7+inE/dNhtW9oscIsjgXlSS0lXzmn0YtN8wVkgguJqRg7tguTe7o27dMHFHJcr51G1z4OikzCgVRJYpKknqqnk9OvvtN019WFVoe/nmvcoMd9440rIYxikYrloucoggd+4Fpew2M13myiSoKu7WTfozTYthlPNZ9mtAiIcM7gWl7DYzjW1di6qakQ7VfCeT/kzTYhjlfJb9GhDiIbJMQSm7zUxX6AJoaMhut4xz7EC7ddKxIno5o1hu0p9pFxIJ2n8S2widgyQOyxBdlsMyfSmdY6xNzSgtiO51dAPS6HgN9zx6SHmHrcvWqGrTicNLNxHmmEP3expZNoOwIY2AjbHYHFOW+CUOkzv3jPBmyHPfVTraLWBvqTUTvMfotSA6uNfxHvvoeA3DuyeUA7tulqd3v06bqkyRurhM+n144wpllsO0ZBDdcZnGW9ZYbI7JJkRzz4gomRGLht8xOscXpFuP7Htea2lctKBH+aU1tQSq8s+E6fesbaO2pBGwLRYHG2OyCblzzwgTXbbo2fLiZId0PvNbR6WV+23jtQQu37w3dFxesrQY2pJGwG+feV6zNsZkE3LnnhEm9rSiW9hMskMG2ff8LJDebUfHa1i/fb+6ArtrfdP1bMMmq6NNsQTt29bzmTUyuGdEUJbDMljY/I7ROT4/+97oeA2vv3VWub1Xb3d7zv32Z7qejdhkdbQpFgcbY7IJkWUywi/LYVne8ruP0c8t46zjdTis375fmYa3izCvRJ2fvj/gadNkPRuxyepoUyw2x2QTYoUsGVEKUXu3S/pLomvbu9wvS+OXXdWOAGCZRj8nAC9u/3Brv3f7VEZ6ybVemGO31X5nYkON2mbax2prn9qOWCE7BK81zJ0z3c8mlqalTNf22Mun2myKfgM7gHl2SQKUGrpbZ3fbL71Qcx2nbdNjt9V+Z2JDDRtfVsdqa58WHdHcS0RUu2WaljJd26qC1n547ZKqgd1dQSmoL7i5Tthjt9V+Z2JDTaLNNI7V1j4tOnLnXiKi2i3TtJTp2tAVtDZpS9emu4JSXOtp2D7J236XRJFy022SPlZb+7ToyOBeIoJ0a2cd0+2SsJTp2nY04bBt+bXZRee0eJMUYl0+MfjZ7JLoq6Q15qBzH+Vcpl3RyekD3VWgyt4pmCOyTImIardM01Kma1tV0LrSRdrqSO54dMfpnthq8mdDN7D7HXsSfZVG6uCgc79hZX8ibSZ1XQRZVAHgtTfOJpJOuVORO/cSoSpEbeKWSdNS5te2qqC1s66f48Pbpt8deFiC3CVJ9JWfxhy1z53t7n10QtkXB45ORm4zjevCpNJWfY5j9UmnE2iFJKJHANwI4FVmvqq57FYADwB4N4CrmXnMtf4WAJ8EMAvgs8y8LygIsUJmTx7Wx6B1o3j/g+yOYXDbKIOI2n9+8YbZvw5dRakk2k4SXZxebIvbNvyskCayzDcAXO9Z9jMAHwXwpGdH7wFwG4Arm9v8DRHpnxWFXEizolCYtoOKYJsWiE4KUy05av8FxZvUO4602k4S03hsi7tIBA7uzPwkgFOeZc8xs8qndDOA7zDzm8z8IoAXAFydSKRCYuRhfTS1YIaJKWwRbT/CaMlR+88v3rTfcdg2JT/oHQFgZ9xFIukXqgMAjrt+P9FcNg8iupOIxohobHIyvB4oRCcP62MYC6bpOlHj7at04fZ1SyOn7o3af36fJ5U6OOu0xFFRxRnnnAjzSfqFqsrqoJTWmPlhAA8DDc094TgEH/RWQsLyzXsjafBBtjYGcPmW77e9IPUrheeO1d2+o3Eve1uvkWbrhQAsXnQeXpx8Db888wYYwMkzM9jy2E9xz65D6K10YebsHJgbds1Na5dg29CqeTFF6T/ddgPNY1y/fX8i70CSSEucRTqALNMndyJJ37mfALDE9fulAF5JeB9CTHSPxLPMkTR4E1ub0z6a7Q/vmcBv3vAf2FWZHZ34nvr5Kd9tdbi3d+KZY2CmPgcGMF2fa1WBmmXGjoPHsHW0XSeP2n86yWTDyv7U3oFEIc13MkJ2JD24Pw7gNiI6j4iWA7gCwE8S3ocQE+8jcdwKRVG07/osQ1VwqYsw77E8SW09CjufPt72e9T+00kmB45OWjX9XtIBlINAWYaIdgK4BsBFRHQCwP1ovGD9bwD6AewlokPMvJGZjxDRowD+EcBZAHcxc37fypik8WiadJt+7fl9lmSFoiSniTO3W99Gx2uBTwRpo/KNe9Mbq1D1i1eK8Du+2tQMRsdrbefzwSeOtBLCVXsreOCmKxOXNiQdQDkIHNyZeZPmo7/TrP9FAF+ME5QNpJGpLuk2/doDzLMdxp1mbpL2wBT3PpO2OkZFdWfu7XsVQf1ncnzuz4f3TLTlu5+aqWN49wSAZLMnpp12QMgGST+gIY1H06Tb9GsvzL7i2udMbG0mePeZtxzjsGntknnLgmIz6T+T43OfT1UhE2cWZ5IUxU4p+CPpBzSk8WiadJtR2tNJBUD0aeZ+Vaacn9255VWopv3bIgN43TKAf2ymBTKSkr2S7iepcFQOZHDXkMajqWmbppWLqn0V5aDptBcmflNbmsk7g0Xn9WDDyn78/cTJQKsjACxuZv+7Z9chjOx7vrVtWv7YqoEF083W0cPYNrSqrdKRjoFqL57afK1Ru6Zylt/5dH+eJGJTLD5SZk+DSlPtrXTHmlhh0qZunY99YKCtchHQyKIIQtvjutMegMziV8VmSqWbAG7ICzaz/vIL8eyxM4FSTJj+NdHt3efTq7kDjWtg5NbVMhB3KFJmLwJpPJqatOlXucjr2qjPMaq9FSw6r8e3vaTiDxNbEITGHefrb54NdRedF0G++m6i0H84VdfDhpX9OHB0UnvOsnDLCOVA7twtwzRbnkMWWfO2jh6ONID74RS8Dnu8NrO4rxIqo2UcpKC0AMide6EIW7kobXva1tHD2HHwWOLtOha/JG2UeePcUadd4FkKSgsmiBXSMsJULsrCnuadnenFpJydCsfiN7xxReQ2bCbNGZ0yg1QwQQZ3y9BNUd82tCqXbH9+UsxANVryLodXpmYwtGYgdBuL+yqo9lZAaOjOjtumy7K/EmlZOWUGqWCCyDIWorOh2WRP6ybCU5uvxfrt+yPLKk4WRZNi2aYWwzjxJE1akpnMIBVMkDt3QYs3G6IbZ9ZmnNmpThZFkxe1pgWehzeuaFhEcyZNyUxmkAomyOAuaNHp7YRzsza9MtLivsaMVBXdRNosikGYFngeWjOA8xcGP5A6MbhDMfkyOMfgLS7hyENZSGZFKcgh5IvIMiUlCauc7o7avdSbqZAZ0N2IzzKDfNr1w5shUcfoeC0w1QEAzDHjJYWFNMiaOcestJ46/X16uo5fnnkDdzdn26ZlUbRJohPsRAb3EpKUVU6nhTt3vaPjNWWmQj/ivIANOobR8VorS2IQfoWk/TR71Xbe/nYXJRGLopAXIsuUkKSscqpsiO7lukyFaWFSMNskjYGfPu33DkG3nV92R7EoCnkhg3sJScoqt21oFW5ft7R1p95NhNvXLW3p7UlY79z6tWNp9COJgtl++rRbzwbOPaX46dpZZ20UBBNElsmJNKePJ2mV2za0CoOXXdiK9cDRyZb27SdhRLE3ulPr6iyNXURa7d1ktutAtVeZYVNXpcrN6HhNWcQ6ipRjO5LeoPjInXsOpF2AOEmrnF+swxtXNLI6eqh0kXJGbZh4/IpQ6/oqyAbpV3A7qP+D+sHvWE1tnLYgBbLLgQzuOZD29PEkrXJ+sQ6tGcDILavb5JRqbwUjt66eN6M2rFXQOYYwxbuH1gxg5NbVqPaei8cZ64MKbpvo+X79oIsVMLdx2oKkNygHpc0K6S6s4EgEphVy0kZnt8siw2NY8ojVLQn4XZ2LXcVK+ipdWNDTjamZeut8L+6rgBk4M2NeEQpor6RkWqDDL1Ybz6sfRbo+O52OywppuzWtSNPHs47VpICFg3ugnq7PYbo+B+Dc+XZ/HiZnvHOdjL18KrAICUFfIcnBxvPqR5GuT0FPKWUZ261pRZo+nnWsthTFdoqQBA3sQc+9tp5XP4p0fQp6Snnnbrs1rUgFiLOONe9z4yYoI6bfHbtTacrW8+pHka5PQU8pB/ciWNPCTB/P25aW5VR3m4p36OycjiZ/76MT2j8ARR8QJb1B8SmlLBNllqGtdJotLU6WySTR2Tl7K93YsLIfWx477HtnX/bzJNhPKQf3KLMMbaXTbGlBtkIdfZWulgXS2TZO5t/zF/ZoC6QcODpp9F6gzOdJsJ9AWYaIHgFwI4BXmfmq5rILAewCsAzASwD+iJlPExEB+AqAGwBMA/hTZn42ndD9KctjZVpVd7KSeqLsZ2jNAO7ZdSjUfqbrc1i86Dw8cNOVrfaXb94bOe7T0/W22agPNQt6AwgVm03vEITOwuTO/RsArvcs2wzgx8x8BYAfN38HgA8BuKL5704AX0smzM7FL3thVLKSeuLsJ8rxeduP+25FF3eYdm14vyN0JoGDOzM/CeCUZ/HNAL7Z/PmbAIZcy7/FDQ4CqBLRxUkF24mkYUvLSuqJs5+o2ru7/ST1+6B2K900L/VB0d7vCOUiqlvmHcx8EgCY+SQRvb25fACAu3zPieayk94GiOhONO7usXTp0ohhlJ80bGlZFViOsx/3cYd1zzjte/uuiwB3huJ3/NYC9HR3G7eva9c5J6plZZAGhWKStBVS9QpLaSlg5ocBPAw00g8kHEepSPr9QRYzEEfHa+jSWAm9+9Hp8s6/sEWvGcCyzXtblsWnNl+LraOHm2UDGd3UcMI4WSjftWUvDNLAt8XtV8RcR9j3D3lbYIViE3Vw/xURXdy8a78YwKvN5ScAuCs8XArglTgBCskzvHHFvCn+SUoIjtauGti9+zGpGjW8cQWGd08YFeJw47S1e+wYnvr5OWVxlhk7Dh4DAAxedqHRwB63f8JWx0qqmpbQuUS1Qj4O4JCUQ9AAABJZSURBVI7mz3cA+J5r+Z9Qg3UAzjjyjWAPaRdY1qUQ6Caatx8TXV6V7dGUmfps28DuZufTx331f3cx7Lj9E/b9Q6dZYIXkMbFC7gRwDYCLiOgEgPsBbAfwKBF9EsAxALc2V/8+GjbIF9CwQn4ihZhzo0yPyWlaRXWa+hzzvH3q1q1NzWD99v1tWvaZmXpbJsi4zDL76v9JZhI1OU5nH6PjNa0MZaO1skzfizIROLgz8ybNRx9UrMsA7ooblI3IY7I5YTR9v3QDtamZRsFrQqtWa1IDO9C4M3/nBQt99fykznPV54+Sex8A2n72Ypu1Ur4X9lLKGappII/J5oSxbwbZFetzHKsId2+lG+svv1D52aa1SwKrNwHJnOegsgnOPvyyYtporZTvhb2UMnFYGmRlHywDYeybcSyPbtZffiFe+ucZbXEWxy0zy/PdMgDwwONHfHO+xz3PZwzyyQftw8bUGfK9sBcZ3A2RAgbtBOmsYTT9qJZHh4FqL24dXNq6W5xzFWd58IkjABqumANHJ1GbmsEcGm6ZHQePodpbwQM3XYlD918HwL8w9/LNe7V/qFT9Abg99sEFw51rSbV/p7C33/7yGPjle2EvIssYIgUMzpFW+gJdwe0glr2ttxUP0D6x4vR0HffunsDw7olzn7tWmJqpY3j3RCt2v8LcumNV9cfwnnP7ZPjnhgfOXUsm15lNmULle2EvMrgbkrZ9sEikpbMOrRnAogXhHyYP/uK0b5bG2Tn29cjX57gVu/c8mxToVvVHfVa9T8deqSsYbnKd2aRzy/fCXkSWCUFZMk3GJU2d1USb9hJ0V2yCO3b3edZllnSvH+a455gDi0wHXWe26dzyvbATuXMXQpNGpsok24gCEZSyhsmxZp0lMs3+F8qDDO5CaNLUWdOoxNTdNT9jo5c5Bob3TMwb4E2ONesskaJzCyaILCOEJs0Cyqq2T7/+Jqbrc5HaW9xXwf0fubLVpp8bpz7b0N69rh9vPCpnkGqdoO2iIgWsBRNkcO8wkrLQxdFZg2yD3riWRayoRADGv3BdW8yj4zXc7VNJSaVbRz3WNLVo0bmFIGRw7yBsmCquimF4zwTAaLlLvNPxo6JKLRzUbhTd2oZ+FQQvorl3EDZY6Extg+7p+FFQadB+U/uBhk4eRbe2oV8FwYvcuXcQNljowuwraly6TI5+7TnafJQ7bRv6VRC8yOBuiC3TveNgMlXc5Djj9IVfFkgvXUT4rYU9vjlfvFR7K3hq87Wt3905Zfy2Gf/CdRgdr2H99v2hj6voU/DjnM8yfC/KisgyBtg03TsOQRY6k+OM2xcmWRgdZpnx+ltnYbg6AOA3b9RbsWwdPYwdB48FTnL6lzfPYuvo4cjHVWRrYpzzWZbvRVmRwd2AsmiqQVPFTY4zbl8MrRnA+QvNHxjrs4wLmlP1TZhjtGJp1EwNZnaOsfPp45GPq8hT8OOcz7J8L8qKyDIGhNFUvY+pG1b248DRyVwfW00fnU2OM6iikMlxToUsuHF6uh6qxJ4jkYRJS6Bb11Q393rP3blq3OjORV7yRpz3BfKuwW5kcDfAVFNVWeKcQszO7zZYD3UxmBynbh3CuUE16Dh1bXQRtMWqw+juhMZxdxuk2XXQrWuqm5v0s26dsZdP4bvP1HKxUsZ5X1D0dw1lR2QZA0w11SCrHWCH9VAXQ9Sp9oT2NLt++/Dbz3k9yVyOjMZxb1q7xGj9SnejeEcc3TyOpBVHEopLnPcFRX7X0AnInbsBptO9TR9HbbAe6mZiAuGn2oct5qzbzz0+M0fD8srUTKvSkvvpyYvbAjl42YWRpZE4klZcSSgOcVIZSBoEuyFOIF1qXAYHB3lsbCzvMGJjWklooNrbZtdLE11MScZguo8gXTlqJSYdi/sqYNZLOov7Kuhb0BM4MJno4UGxdxPhvB5S5sjxk490nn0hGYpu5SSiZ5h5UPWZyDIJYpLRMOvH1iwenZOqHpR0RsjT03XtwF7pJrz2xtlAG5+p3S8o9llmTNfn5tk6eyvdSknIQeyF6VF2K6cM7gmissTdvm5prha5LGx6SVUPctpRVT9ycD6r9jaqGEVhoNqLRQt6tCkP3Ji+s/D2gQ5u7t/dT9uGVrW2VSH2wnQou5VTNPeESTpbXxKPjVlkEEyyepCfw2WWGd1EodwzKnTbey2dYd4nuPtAl8mSGUo5zNl2+ea9815O6/ZnQtFlhzQpu5VT7twtpkyPjSbVg0yyNgLxy+r5aeOOpdPpb91deJDdT/f04fdU4tdunGyVZbh+0qDsFa1kcLeYMj02mujyJlbSNFFZOrm53I3JOwudDTPInpnkO5IyXT9pUHYrp8gyFlOmx0YT21yc4yKES0rmZcBnW0cnDyNtODZMJ2lZNzW89M5yHUnaC8t0/aRB2a2csQZ3IvocgH+HxnfrfzDzl4noQgC7ACwD8BKAP2Lm0zHj7EhsmwEYV791a9JOW/fsOtRqK87gDAAbVvbj2wePKTVrPxzLps7OaJrXxsu2oVWBg7mKpN6RVPsqOK1I9VAW2SEJylzRKrIsQ0RXoTGwXw1gNYAbiegKAJsB/JiZrwDw4+bvQgRsemxMUr/VtbVhZb9xxkgvjMZkpShq/IaV/QD0ha5NLJO2MTpew2tvnJ23PGpBEqF4xNHc3w3gIDNPM/NZAP8A4N8AuBnAN5vrfBPAULwQOxebsg0mqd/q2jpwdFKbMbK30qW1CsblwNFJAOr+NrVM2sbIvufnxQ0Aixb0lPZOVWgnjizzMwBfJKK3AZgBcAOAMQDvYOaTAMDMJ4no7aqNiehOAHcCwNKlS2OEUQ50koctj40m+q2JbLN19LBWevGTZGbqc632dHbBqOiO7fU3z2otk1F06yxtibr4zkSwkIqdsphEHtyZ+Tki+o8AfgTgNQATAOY/B+q3fxjAw0Aj/UDUOMpAEQosB+n/JsfgFM+IyvCeCd9YoqI7Bj8vfVjdOutznNT7miJcm4KaWFZIZv46M7+fmX8fwCkA/w/Ar4joYgBo/v9q/DDLTREsa0H6v8kxmBbP0FGfZYzsex7DG1egO6I27yXoGIK2MSXrc5zU+5oiXJuCmrhumbcz86tEtBTARwH8HoDlAO4AsL35//diR1lyimBZC7KNmRxD3MlHTnvOPu+OmUXSm5TLtL+jvPfI+hwnZfMrwrUpqInrc/9uU3OvA7iLmU8T0XYAjxLRJwEcA3Br3CDLTphH6Cz0z9HxGh54/EhLlnCnxdVZGS/orShljGpfpTWdPwm6iLB8815c0MwtE/XPxeK+Sqti0tjLp7D3pyeN23K2CVNhKw1bq0nVL5PMn37XlG12XB3yXmA+kvLXAry6JtB4hPbeIZquFzeW4d0T85wWlW7CyC2rWyXhvHF0dxFmFe6MLgDzk9yWj6DzkPS5U7UXNiaTuLK45uJShBjTQlL+Wo6p5TEL/VNnoXP0bl0cqoEd6IyBHQg+D0nbWpOq+hV0Tdlkx9Uh7wXUSPoBSzCxPGahf/q15XwmequaoH4xLaLthyM/mLqFalMzWL55b+jqYe7lftemDXKIvBdQI3fuBSKLLHYX9Oqn2jv7sU1vtYWgfok7y9e9fRj89hXnmrIl62TZsztGRQb3ApFFOgK/jLTOfpKomJSMkdEeTM5DXPkgbtZM1b7iXFO2yCE2pemwCZFlCkQWWeymFImmvPv3xhHllXz+r/GTySQZ5jzElQ/81hvwuGV0/ettI841ZYscUvbsjlGRwb1gpJ2OQDfYOXldvBrrQx9/n1YD9iv8bPJ5mlR7Kzh0/3UYHa/h3kcnQscRpcC4rm8ZjQLbUe2UqkLkumNSSRVRrymbbJK2pOmwCZFlhDb8HnH9sjmqttm0dgkq3XoBJq+BHQBef+ssto4expbHDkeKw8kkGQY/OctErw5TiFx1THkURhfyQwZ3oQ0/65tfNkfVNtuGVmHkltWR86GnSX2WsfPp45E1bCeTZBjcfasiCTulTpfvJsqlMLqQHzKJqQOJal/TZWMkAC9u/7B2P7WpmVwlmDTQHbMpfpktnXcBqhmn3klt3vN4z65Doc6RkB9J2Ej9JjGJ5t5hxMnyFzZNgns/tmrvUYmrK/u9yHUkL3cGTe950p1HXRqITrcF2kYW2TZFlukw4tjXwmisYTIsblq7JLa1MksIiK0rR7GTus+T7jwSQXTwApCFjVQG9w4jjn0tjMZq0p5bm//SR8PXGiVEr28aB0b8uytvX5oSNEt4arouOngByMJGWnpZxobp0TYR1r6m6j8/C6CzvonIUpuawb2PTuDuXYdCD9JEwItfamjIa/79D5WFoNMiqXJ/bvuerji3F/csYd15FFug/WRhIy31nbst06NtIoy0Erb/okyPd7T2sIMzNfenKwSdFmlJHCYyjXvfYkMsNlmcv1LfufvpWp16ZxNmNl/Y/os7PT4Mc4yWPqnKYpkUXQT89sIKzszUU33yU50XP7eMzMosNlmcv1JbIcNa94R2wvZf0oWrg3C06jT3KdeKYDMdm89dssXFI2z/6ZZ3+2Uji8El1d7Q5zJsLHKtCEWl1IO76JLxCNt/uvWD0hBEwYkjjKUwrO1SrhWhyJRacxddMh5h+89v/cHLLsSDTxxpvTglApjPTWBa3FcBMzA1U2+rjdpFDX3d+VynfXtnwnqzJHpjcWKs9lXwZn0W0/W5tri8xbMFoWiUWnMXBEEoMx2ruQuCIHQqMrgLgiCUEBncBUEQSogM7oIgCCVEBndBEIQSYoVbhogmAbycwa4uAvDrDPYTB4kxPrbHB0iMSdHpMV7GzMqaj1YM7llBRGM625AtSIzxsT0+QGJMColRj8gygiAIJUQGd0EQhBLSaYP7w3kHYIDEGB/b4wMkxqSQGDV0lOYuCILQKXTanbsgCEJHIIO7IAhCCem4wZ2IPkNEzxPRESL6T3nHo4OI/oKImIguyjsWL0Q0QkRHieinRPR3RFTNOyYHIrq+eX5fIKLNecfjhYiWENEBInqueQ1+Lu+YdBBRNxGNE9Hf5x2LCiKqEtGe5rX4HBH9Xt4xeSGie5rn+WdEtJOIFma1744a3IloA4CbAbyXma8E8J9zDkkJES0B8IcAjuUdi4YfAbiKmd8L4J8AbMk5HgCNwQjAfwfwIQDvAbCJiN6Tb1TzOAvgXmZ+N4B1AO6yMEaHzwF4Lu8gfPgKgP/NzCsBrIZlsRLRAIDPAhhk5qsAdAO4Lav9d9TgDuDPAWxn5jcBgJlfzTkeHQ8B+EukWx40Msz8Q2Y+2/z1IIBL84zHxdUAXmDmXzDzWwC+g8Yfc2tg5pPM/Gzz539BY0CyriIIEV0K4MMA/jbvWFQQ0W8D+H0AXwcAZn6LmafyjUpJD4BeIuoB0Afglax23GmD++8A+NdE9DQR/QMR/W7eAXkhopsA1Jh5Iu9YDPkzAD/IO4gmAwCOu34/AQsHTgciWgZgDYCn841EyZfRuMGYyzsQDe8CMAngfzalo78lokV5B+WGmWtoqAPHAJwEcIaZf5jV/ktXZo+I/g+Adyo+ug+N412MxuPw7wJ4lIjexRn7QQNi/GsA12UZjwq/GJn5e8117kNDZvh2lrH5oCrUauXTDxGdD+C7AO5m5t/kHY8bIroRwKvM/AwRXZN3PBp6ALwfwGeY+Wki+gqAzQA+n29Y5yCixWg8OS4HMAVgNxHdzsw7sth/6QZ3Zv4D3WdE9OcAHmsO5j8hojk0kvpMZhUfoI+RiFahcSFMEBHQkDueJaKrmfmXGYbo248AQER3ALgRwAez/uPowwkAS1y/X4oMH4NNIaIKGgP7t5n5sbzjUbAewE1EdAOAhQB+m4h2MPPtOcfl5gSAE8zsPPXsQWNwt4k/APAiM08CABE9BuBfAchkcO80WWYUwLUAQES/A2ABLMoox8yHmfntzLyMmZehcQG/P+uBPQgiuh7AXwG4iZmn847Hxf8FcAURLSeiBWi8vHo855jaoMZf7a8DeI6Z/0ve8ahg5i3MfGnzGrwNwH7LBnY0vxPHiWhFc9EHAfxjjiGpOAZgHRH1Nc/7B5HhS9/S3bkH8AiAR4joZwDeAnCHRXedReKrAM4D8KPmE8ZBZv5UviEBzHyWiD4NYB8azoRHmPlIzmF5WQ/g3wI4TESHmsv+mpm/n2NMReUzAL7d/EP+CwCfyDmeNppy0R4Az6IhX44jw1QEkn5AEAShhHSaLCMIgtARyOAuCIJQQmRwFwRBKCEyuAuCIJQQGdwFQRBKiAzugiAIJUQGd0EQhBLy/wHSY/JkAE7j5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#labels = y\n",
    "#features = x\n",
    "print(features[:,0].size, labels.size)\n",
    "scatter(features[:,3],labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-174-caf74d5af4d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# Pull out one tree from the forest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import tools needed for visualization\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydot\n",
    "# Pull out one tree from the forest\n",
    "tree = rf.estimators_[5]\n",
    "# Export the image to a dot file\n",
    "export_graphviz(tree, out_file = 'tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "# Use dot file to create a graph\n",
    "(graph, ) = pydot.graph_from_dot_file('tree.dot')\n",
    "# Write graph to a png file\n",
    "graph.write_png('tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_small = RandomForestRegressor(n_estimators=10, max_depth = 3)\n",
    "rf_small.fit(train_features, train_labels)\n",
    "# Extract the small tree\n",
    "tree_small = rf_small.estimators_[5]\n",
    "# Save the tree as a png image\n",
    "export_graphviz(tree_small, out_file = 'small_tree.dot', feature_names = feature_list, rounded = True, precision = 1)\n",
    "(graph, ) = pydot.graph_from_dot_file('small_tree.dot')\n",
    "graph.write_png('small_tree.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: SubCortGrayVol       Importance: 0.36\n",
      "Variable: TotalGrayVol         Importance: 0.31\n",
      "Variable: CortexVol            Importance: 0.3\n",
      "Variable: GenderTwin           Importance: 0.03\n"
     ]
    }
   ],
   "source": [
    "#Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# Set the style\n",
    "plt.style.use('fivethirtyeight')\n",
    "# list of x locations for plotting\n",
    "x_values = list(range(len(importances)))\n",
    "# Make a bar chart\n",
    "plt.bar(x_values, importances, orientation = 'vertical')\n",
    "# Tick labels for x axis\n",
    "plt.xticks(x_values, feature_list, rotation='vertical')\n",
    "# Axis labels and title\n",
    "plt.ylabel('Importance'); plt.xlabel('Variable'); plt.title('Variable Importances');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
